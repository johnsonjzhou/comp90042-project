{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 03 inference\n",
    "\n",
    "Evidence retrieval using a siamese BERT classification model. This is similar to Model 01 except this does not use any community based models from sentence transformer.\n",
    "\n",
    "On additional training using increased negative samples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to project root\n",
    "from pathlib import Path\n",
    "import os\n",
    "ROOT_DIR = Path.cwd()\n",
    "while not ROOT_DIR.joinpath(\"src\").exists():\n",
    "    ROOT_DIR = ROOT_DIR.parent\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = ROOT_DIR.joinpath(\"./result/models/*\")\n",
    "OUTPUT_PATH = ROOT_DIR.joinpath(\"./result/inference/*\")\n",
    "DATA_PATH = ROOT_DIR.joinpath(\"./data/*\")\n",
    "NER_PATH = ROOT_DIR.joinpath(\"./result/ner/*\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/comp90042_project/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device is 'mps'\n"
     ]
    }
   ],
   "source": [
    "# Imports and dependencies\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Linear, Module, CrossEntropyLoss, Dropout, CosineSimilarity\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from torch.nn.functional import relu, softmax\n",
    "from torcheval.metrics import BinaryAccuracy, BinaryF1Score, BinaryRecall\n",
    "\n",
    "from src.torch_utils import get_torch_device\n",
    "from src.data import create_claim_output\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Union, Tuple, Dict\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from math import exp\n",
    "from collections import defaultdict\n",
    "\n",
    "TORCH_DEVICE = get_torch_device()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ClaimEvidencePair:\n",
    "    claim_id:str\n",
    "    evidence_id:str\n",
    "    label:int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceClaims(Dataset):\n",
    "    \n",
    "    def __init__(self, claims_path:Path) -> None:\n",
    "        super(InferenceClaims, self).__init__()\n",
    "        with open(claims_path, mode=\"r\") as f:\n",
    "            self.claims = json.load(fp=f)\n",
    "            self.claim_ids = list(self.claims.keys())\n",
    "            print(f\"loaded inference claims n={len(self.claim_ids)}\")\n",
    "        return\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.claim_ids)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[str]:\n",
    "        claim_id = self.claim_ids[idx]\n",
    "        claim_text = self.claims[claim_id][\"claim_text\"]\n",
    "        return claim_id, claim_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDatasetInference(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        claim_id:str,\n",
    "        claims_path:Path,\n",
    "        evidence_path:Path,\n",
    "        claims_shortlist:Path = None,\n",
    "        evidence_shortlist:Path = None,\n",
    "        verbose:bool=True\n",
    "    ) -> None:\n",
    "        super(SiameseDatasetInference, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        self.claim_id = claim_id\n",
    "        \n",
    "        # Load claims text from json\n",
    "        with open(claims_path, mode=\"r\") as f:\n",
    "            claims = json.load(fp=f)\n",
    "            self.claim_text = claims[self.claim_id][\"claim_text\"]\n",
    "            \n",
    "        # Load evidence library\n",
    "        with open(evidence_path, mode=\"r\") as f:\n",
    "            self.evidence = json.load(fp=f)\n",
    "        \n",
    "        # Load the pre-retrieved shortlist of evidences\n",
    "        # From either a pre-retrieved list of evidences specific for the\n",
    "        # claim_id or from a pre-collated evidence shortlist\n",
    "        # Both of which were determined from the fast shortlisting process\n",
    "        if claims_shortlist is not None:\n",
    "            with open(claims_shortlist, mode=\"r\") as f:\n",
    "                claims_shortlist_ = json.load(fp=f)\n",
    "                self.evidence_shortlist = list(set(\n",
    "                    claims_shortlist_.get(self.claim_id, [])\n",
    "                ))\n",
    "                print(f\"loaded claims_shortlist: {claims_shortlist}\")\n",
    "        elif evidence_shortlist is not None:\n",
    "            with open(evidence_shortlist, mode=\"r\") as f:\n",
    "                self.evidence_shortlist = list(set(json.load(fp=f)))\n",
    "                print(f\"loaded evidence_shortlist: {evidence_shortlist}\")\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"Provide either a claims_shortlist or evidence_shortlist\"\n",
    "            )\n",
    "\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.evidence_shortlist)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[str]:\n",
    "        # Get text ids\n",
    "        claim_id = self.claim_id\n",
    "        evidence_id = self.evidence_shortlist[idx]\n",
    "        \n",
    "        # Get text\n",
    "        claim_text = self.claim_text\n",
    "        evidence_text = self.evidence[evidence_id]\n",
    "\n",
    "        return (claim_text, evidence_text, claim_id, evidence_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseClassifierBert(Module):\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            pretrained_name:str,\n",
    "            device,\n",
    "            **kwargs\n",
    "        ) -> None:\n",
    "        super(SiameseClassifierBert, self).__init__(**kwargs)\n",
    "        self.device = device\n",
    "        \n",
    "        # Use a pretrained tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_name)\n",
    "        \n",
    "        # Use a pretrained model\n",
    "        self.bert = BertModel.from_pretrained(pretrained_name)\n",
    "        self.bert.to(device=device)\n",
    "        \n",
    "        # Classification layers\n",
    "        self.linear1 = Linear(2304, 1024, bias=True, device=device)\n",
    "        self.linear2 = Linear(1024, 512, bias=True, device=device)\n",
    "        self.linear3 = Linear(512, 2, bias=True, device=device)\n",
    "        self.relu = relu\n",
    "        self.softmax = softmax\n",
    "        self.dropout_in = Dropout(p=0.2)\n",
    "        self.dropout_out = Dropout(p=0.5)\n",
    "        \n",
    "        # print(self.tokenizer)\n",
    "        # print(self.bert)\n",
    "        # print(self.linear1)\n",
    "        # print(self.linear2)\n",
    "        # print(self.activation)\n",
    "        # print(self.softmax)\n",
    "        return\n",
    "        \n",
    "    def forward(self, claim_texts, evidence_texts) -> Tuple[torch.Tensor]:\n",
    "        \n",
    "        # Run the tokenizer\n",
    "        t_kwargs = {\n",
    "            \"return_tensors\": \"pt\",\n",
    "            \"padding\": True,\n",
    "            \"truncation\": True,\n",
    "            \"max_length\": 100,\n",
    "            \"add_special_tokens\":True\n",
    "        }\n",
    "        claim_x = self.tokenizer(claim_texts, **t_kwargs)\n",
    "        evidence_x = self.tokenizer(evidence_texts, **t_kwargs)\n",
    "        \n",
    "        claim_x = claim_x[\"input_ids\"].to(device=self.device)\n",
    "        evidence_x = evidence_x[\"input_ids\"].to(device=self.device)\n",
    "        \n",
    "        # Run Bert\n",
    "        claim_x = self.bert(claim_x, return_dict=True).pooler_output\n",
    "        evidence_x = self.bert(evidence_x, return_dict=True).pooler_output\n",
    "        # dim=768\n",
    "        \n",
    "        # Concatenate the two embeddings\n",
    "        x = torch.cat((claim_x, evidence_x, claim_x - evidence_x), dim=1)\n",
    "        # dim=2304\n",
    "        \n",
    "        # Run classification layers\n",
    "        x = self.dropout_in(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout_out(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout_out(x)\n",
    "        x = self.linear3(x)\n",
    "        \n",
    "        # Create the predictions\n",
    "        y = self.softmax(x, dim=-1)\n",
    "        \n",
    "        return (y, claim_x, evidence_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f\"model_03_base_run_01_continue.pth\"\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL_PATH.with_name(MODEL_NAME), mode=\"rb\") as f:\n",
    "    model = torch.load(f, map_location=TORCH_DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EvidenceScore:\n",
    "    evidence_id:str\n",
    "    score:float\n",
    "    \n",
    "    def to_list(self) -> List[str]:\n",
    "        return [self.evidence_id, str(self.score)]\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, str]:\n",
    "        return {\"evidence_id\": self.evidence_id, \"score\": str(self.score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_run(\n",
    "    claims_path:Path,\n",
    "    evidence_path:Path,\n",
    "    claims_shortlist:Path = None,\n",
    "    evidence_shortlist:Path = None,\n",
    "    save_path:Path = None,\n",
    "    batch_size:int = 64\n",
    "):\n",
    "    # Generate claims iterations\n",
    "    inference_claims = InferenceClaims(claims_path=claims_path)\n",
    "    \n",
    "    # Cumulator\n",
    "    claim_predictions = dict()\n",
    "    \n",
    "    # Load from save to continue inference if exists\n",
    "    saved_predictions = dict()\n",
    "    if save_path.exists():\n",
    "        with open(save_path, mode=\"r\") as f:\n",
    "            saved_predictions.update(json.load(fp=f))\n",
    "    \n",
    "    for claim_id, claim_text in inference_claims:\n",
    "        \n",
    "        # Skip if a save entry exists\n",
    "        if claim_id in saved_predictions.keys():\n",
    "            print(f\"skipping {claim_id}, done previously\")\n",
    "            continue\n",
    "        \n",
    "        # Create a save entry\n",
    "        claim_predictions[claim_id] = {\n",
    "            \"claim_text\": claim_text,\n",
    "            \"evidences\": []\n",
    "        }\n",
    "        \n",
    "        # Generate claims-evidence inference interations\n",
    "        infer_data = SiameseDatasetInference(\n",
    "            claim_id=claim_id,\n",
    "            claims_path=claims_path,\n",
    "            evidence_path=evidence_path,\n",
    "            claims_shortlist=claims_shortlist,\n",
    "            evidence_shortlist=evidence_shortlist,\n",
    "        )\n",
    "        infer_dataloader = DataLoader(\n",
    "            dataset=infer_data,\n",
    "            shuffle=False,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        \n",
    "        print(f\"running inference for {claim_id} n={len(infer_data)}\")\n",
    "    \n",
    "        # Set model mode to evaluation\n",
    "        model.eval()\n",
    "        \n",
    "        infer_batches = tqdm(infer_dataloader, desc=\"infer batches\")\n",
    "        for batch in infer_batches:\n",
    "            claim_texts, evidence_texts, batch_claim_ids, batch_evidence_ids = batch\n",
    "            \n",
    "            # Forward\n",
    "            predictions, claim_emb, evidence_emb = model(claim_texts, evidence_texts)\n",
    "            \n",
    "            # Prediction\n",
    "            _, predicted_labels = torch.max(predictions, dim=-1)\n",
    "            \n",
    "            # Score embeddings with cosine similarity\n",
    "            cos_sim = CosineSimilarity(dim=1)\n",
    "            scores = cos_sim(claim_emb, evidence_emb)\n",
    "            \n",
    "            for c_id, e_id, predicted_label, score in zip(\n",
    "                batch_claim_ids, batch_evidence_ids,\n",
    "                predicted_labels.cpu().numpy(),\n",
    "                scores.cpu().detach().numpy()\n",
    "            ):\n",
    "                if predicted_label == 1:\n",
    "                    claim_predictions[c_id][\"evidences\"].append(EvidenceScore(\n",
    "                        evidence_id=e_id,\n",
    "                        score=score\n",
    "                    ))\n",
    "            \n",
    "            continue\n",
    "    \n",
    "        # Save on every claim_id\n",
    "        if save_path:\n",
    "            # Retrieve at most 5 top predicted evidences by score\n",
    "            claim_predictions_output = dict()\n",
    "            for claim_id_, claim_ in claim_predictions.items():\n",
    "                claim_ = claim_.copy()\n",
    "                claim_[\"evidences\"] = [\n",
    "                    evidence_score.evidence_id\n",
    "                    for evidence_score in sorted(\n",
    "                        claim_[\"evidences\"],\n",
    "                        key=lambda es: es.score,\n",
    "                        reverse=True\n",
    "                    )\n",
    "                ][:5]\n",
    "                claim_predictions_output[claim_id_] = claim_\n",
    "            \n",
    "            # Make a copy of existing saved results and add the new results\n",
    "            # for this run\n",
    "            save_dict = saved_predictions.copy()\n",
    "            save_dict.update(claim_predictions_output)\n",
    "\n",
    "            with open(save_path, mode=\"w\") as f:\n",
    "                json.dump(obj=save_dict, fp=f)\n",
    "                print(f\"saved to: {save_path}\")\n",
    "    \n",
    "        continue\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded inference claims n=154\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-752 n=1564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 25/25 [00:05<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-375 n=3682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 58/58 [00:15<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1266 n=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-871 n=2111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 33/33 [00:07<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2164 n=2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 32/32 [00:06<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1607 n=3710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 58/58 [00:11<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-761 n=1075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 17/17 [00:04<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1718 n=1169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 19/19 [00:04<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1273 n=8586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 135/135 [00:38<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1786 n=132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 3/3 [00:01<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2796 n=3903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 61/61 [00:15<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2580 n=2105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 33/33 [00:07<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1219 n=4664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 73/73 [00:17<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-75 n=1554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2813 n=2959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 47/47 [00:11<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2335 n=3631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 57/57 [00:13<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-161 n=2197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 35/35 [00:07<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2243 n=6117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 96/96 [00:21<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1256 n=701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 11/11 [00:02<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-506 n=4723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 74/74 [00:20<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-369 n=1984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 31/31 [00:06<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2184 n=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1057 n=3478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 55/55 [00:11<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-104 n=2806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 44/44 [00:09<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1975 n=6634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 104/104 [00:27<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-139 n=91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 2/2 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2062 n=4300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 68/68 [00:15<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1160 n=3890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 61/61 [00:14<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2679 n=3162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 50/50 [00:12<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2662 n=3477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 55/55 [00:15<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1490 n=6696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 105/105 [00:26<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2768 n=933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 15/15 [00:04<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2168 n=1406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 22/22 [00:05<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-785 n=3402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 54/54 [00:13<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2426 n=1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 30/30 [00:07<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1292 n=2162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 34/34 [00:08<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-993 n=8185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 128/128 [00:34<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2593 n=1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 25/25 [00:07<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1567 n=1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 27/27 [00:06<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1834 n=6075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 95/95 [00:23<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-856 n=3509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 55/55 [00:17<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-540 n=43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-757 n=1689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 27/27 [00:06<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1407 n=4756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 75/75 [00:19<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-3070 n=3882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 61/61 [00:15<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1745 n=698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 11/11 [00:03<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1515 n=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1519 n=6585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 103/103 [00:26<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-3069 n=2974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 47/47 [00:13<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-677 n=2973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 47/47 [00:11<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-765 n=1753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 28/28 [00:06<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2275 n=1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 31/31 [00:06<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1113 n=2746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 43/43 [00:09<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2611 n=2533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 40/40 [00:09<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2060 n=2667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 42/42 [00:08<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2326 n=1835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 29/29 [00:06<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1087 n=2464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 39/39 [00:09<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2867 n=1254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 20/20 [00:05<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2300 n=1414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 23/23 [00:05<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2250 n=3883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 61/61 [00:18<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2429 n=5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 92/92 [00:29<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-3051 n=7902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 124/124 [00:32<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1549 n=1768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 28/28 [00:06<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-261 n=1727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 27/27 [00:07<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2230 n=4579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 72/72 [00:16<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2579 n=4509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 71/71 [00:16<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1416 n=7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 120/120 [00:33<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2497 n=2149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 34/34 [00:07<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-811 n=5696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 89/89 [00:22<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1896 n=4296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 68/68 [00:15<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2819 n=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2643 n=2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 37/37 [00:10<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1775 n=5493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 86/86 [00:21<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-316 n=1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 30/30 [00:07<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-896 n=9240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 145/145 [00:37<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-331 n=2684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 42/42 [00:09<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2574 n=1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 20/20 [00:05<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-342 n=2809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 44/44 [00:11<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2034 n=1957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 31/31 [00:07<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-578 n=4641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 73/73 [00:19<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-976 n=1870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 30/30 [00:07<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1097 n=3177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 50/50 [00:14<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-609 n=4013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 63/63 [00:18<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-173 n=1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 21/21 [00:05<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1222 n=1307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 21/21 [00:06<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2441 n=1325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 21/21 [00:05<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-756 n=4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 64/64 [00:16<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2577 n=3913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 62/62 [00:16<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2890 n=1976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 31/31 [00:07<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2478 n=1631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 26/26 [00:07<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2399 n=4401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 69/69 [00:17<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-3091 n=4126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 65/65 [00:15<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-141 n=1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 24/24 [00:05<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1933 n=2705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 43/43 [00:10<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1689 n=2980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 47/47 [00:12<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-443 n=4406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 69/69 [00:16<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2037 n=1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 19/19 [00:04<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1734 n=1986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 32/32 [00:07<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2093 n=2382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 38/38 [00:10<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1400 n=2404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 38/38 [00:08<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1638 n=1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 30/30 [00:07<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-3075 n=3526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 56/56 [00:14<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-38 n=2219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 35/35 [00:08<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1643 n=453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 8/8 [00:02<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1259 n=3164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 50/50 [00:14<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1605 n=1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 18/18 [00:05<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1711 n=3307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 52/52 [00:12<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2236 n=4069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 64/64 [00:14<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1040 n=5067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 80/80 [00:24<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-392 n=4018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 63/63 [00:14<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-368 n=4175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 66/66 [00:16<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-559 n=3715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 59/59 [00:15<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2583 n=4244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 67/67 [00:15<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2609 n=3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 49/49 [00:11<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-492 n=5459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 86/86 [00:21<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1420 n=4985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 78/78 [00:19<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1089 n=3804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 60/60 [00:20<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1467 n=2787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 44/44 [00:10<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-444 n=1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 27/27 [00:06<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-803 n=4131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 65/65 [00:18<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1668 n=1066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 17/17 [00:04<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-742 n=356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 6/6 [00:02<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-846 n=6266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 98/98 [00:31<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2119 n=393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 7/7 [00:02<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1167 n=2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 34/34 [00:09<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-623 n=2679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 42/42 [00:10<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2882 n=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1698 n=4989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 78/78 [00:16<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-181 n=1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 30/30 [00:06<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-281 n=6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 109/109 [00:26<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2809 n=4070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 64/64 [00:15<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1928 n=1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 20/20 [00:05<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2787 n=4219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 66/66 [00:16<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-478 n=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-988 n=439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 7/7 [00:03<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-266 n=630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 10/10 [00:02<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2282 n=2246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 36/36 [00:08<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2895 n=4022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 63/63 [00:15<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-349 n=3985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 63/63 [00:14<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2101 n=1227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 20/20 [00:05<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-897 n=907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 15/15 [00:04<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-3063 n=2151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 34/34 [00:08<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-386 n=10047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 157/157 [00:45<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2691 n=1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 25/25 [00:06<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-530 n=2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 32/32 [00:08<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2979 n=4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 71/71 [00:17<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-665 n=2861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 45/45 [00:13<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-199 n=3545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 56/56 [00:12<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-490 n=1183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 19/19 [00:04<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-2400 n=1965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 31/31 [00:09<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-204 n=2938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 46/46 [00:10<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1426 n=1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 20/20 [00:04<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-698 n=3627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 57/57 [00:17<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n",
      "loaded claims_shortlist: /Users/johnsonzhou/git/comp90042-project/result/ner/dev_claim_evidence_retrieved.json\n",
      "running inference for claim-1021 n=2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "infer batches: 100%|██████████| 32/32 [00:08<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: /Users/johnsonzhou/git/comp90042-project/result/inference/model_03_run_01_continue_dev_claim_evidence_retrieved.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inference_run(\n",
    "    claims_path=DATA_PATH.with_name(\"dev-claims.json\"),\n",
    "    evidence_path=DATA_PATH.with_name(\"evidence.json\"),\n",
    "    claims_shortlist=NER_PATH.with_name(\"dev_claim_evidence_retrieved.json\"),\n",
    "    # evidence_shortlist=NER_PATH.with_name(\"shortlist_dev_claim_evidence_retrieved.json\"),\n",
    "    save_path=OUTPUT_PATH.with_name(\"model_03_run_01_continue_dev_claim_evidence_retrieved.json\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_run(\n",
    "#     claims_path=DATA_PATH.with_name(\"test-claims-unlabelled.json\"),\n",
    "#     evidence_path=DATA_PATH.with_name(\"evidence.json\"),\n",
    "#     # claims_shortlist=NER_PATH.with_name(\"test_claim_evidence_retrieved.json\"),\n",
    "#     evidence_shortlist=NER_PATH.with_name(\"shortlist_test_claim_evidence_retrieved.json\"),\n",
    "#     save_path=OUTPUT_PATH.with_name(\"model_03_run_01_test_claim_evidence_retrieved.json\")\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp90042_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
