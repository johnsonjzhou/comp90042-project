{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 01 inference\n",
    "\n",
    "Evidence retrieval using a Siamese BERT classification model.\n",
    "\n",
    "Ref:\n",
    "- [STS continue training guide](https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/sts/training_stsbenchmark_continue_training.py)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to project root\n",
    "import pathlib\n",
    "import os\n",
    "ROOT_DIR = pathlib.Path.cwd()\n",
    "while not ROOT_DIR.joinpath(\"src\").exists():\n",
    "    ROOT_DIR = ROOT_DIR.parent\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = ROOT_DIR.joinpath(\"./result/models/*\")\n",
    "OUTPUT_PATH = ROOT_DIR.joinpath(\"./result/inference\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/comp90042_project/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device is 'mps'\n"
     ]
    }
   ],
   "source": [
    "# Imports and dependencies\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, util\n",
    "from src.torch_utils import get_torch_device\n",
    "from src.data import load_from_json\n",
    "from src.model_01 import run_inference\n",
    "import logging\n",
    "import random\n",
    "random.seed(a=42)\n",
    "\n",
    "torch_device = get_torch_device()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = MODEL_PATH.with_name(f\"model_01_base_e5_equal_neg\")\n",
    "inference_output_path = OUTPUT_PATH.joinpath(model_save_path.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level=logging.INFO,\n",
    "    handlers=[LoggingHandler()]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train-claims\n",
      "Loaded dev-claims\n",
      "Loaded test-claims-unlabelled\n",
      "Loaded evidence\n"
     ]
    }
   ],
   "source": [
    "data_names = [\"train-claims\", \"dev-claims\", \"test-claims-unlabelled\", \"evidence\"]\n",
    "train_claims, dev_claims, test_claims, all_evidence = load_from_json(data_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "154\n",
      "1208827\n"
     ]
    }
   ],
   "source": [
    "print(len(test_claims))\n",
    "print(len(dev_claims))\n",
    "print(len(all_evidence))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As `all_evidence` exceeds maximum size limit for `tensor.save`, we will test with a reduced set for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3443"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract a set of named evidence ids\n",
    "related_evidence_ids = set()\n",
    "for dataset in [train_claims, dev_claims]:\n",
    "    for claim in dataset.values():\n",
    "        related_evidence_ids.update(set(claim[\"evidences\"]))\n",
    "len(related_evidence_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_evidence_ids = random.sample(\n",
    "    population=set(all_evidence.keys()),\n",
    "    k=5000\n",
    ")\n",
    "len(random_evidence_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8431"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_lib_ids = related_evidence_ids.union(random_evidence_ids)\n",
    "len(evidence_lib_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_evidence = {k:v for k, v in all_evidence.items() if k in evidence_lib_ids}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select load model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-27 22:34:23 - Load pretrained SentenceTransformer: /Users/johnsonzhou/git/comp90042-project/result/models/model_01_base_e5_equal_neg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(\n",
    "    model_name_or_path=model_save_path,\n",
    "    device=torch_device\n",
    ")\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate claim embeddings n=154\n",
      "Loaded claim embeddings from file\n",
      "Generate evidence embeddings n=8431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 132/132 [00:14<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved evidence embeddings to file\n",
      "Calculate scores\n",
      "Retrieve top scoring evidences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 154it [00:00, 978.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average retrievals = 511.227273\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_inference(\n",
    "    name=\"dev\",\n",
    "    model=model,\n",
    "    claims=dev_claims,\n",
    "    evidence=reduced_evidence,\n",
    "    scorer=util.dot_score,\n",
    "    threshold=195.8921,\n",
    "    output_path=inference_output_path,\n",
    "    batch_size=64,\n",
    "    device=torch_device,\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp90042_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
