{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 03a\n",
    "\n",
    "Evidence retrieval using a Siamese BERT classification model.\n",
    "This is similar to Model 01, however, it only uses official pre-trained models from hugging face.\n",
    "\n",
    "Ref:\n",
    "- [Hugging face pre-trained models](https://huggingface.co/transformers/v3.3.1/pretrained_models.html)\n",
    "- [Hugging face guide to fine-tuning](https://huggingface.co/transformers/v3.3.1/custom_datasets.html)\n",
    "- [Hugging face guide to fine-tuning easy](https://huggingface.co/docs/transformers/training)\n",
    "- [SO Guide](https://stackoverflow.com/a/64156912)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to project root\n",
    "from pathlib import Path\n",
    "import os\n",
    "ROOT_DIR = Path.cwd()\n",
    "while not ROOT_DIR.joinpath(\"src\").exists():\n",
    "    ROOT_DIR = ROOT_DIR.parent\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = ROOT_DIR.joinpath(\"./result/models/*\")\n",
    "DATA_PATH = ROOT_DIR.joinpath(\"./data/*\")\n",
    "NER_PATH = ROOT_DIR.joinpath(\"./result/ner/*\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/comp90042_project/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device is 'mps'\n"
     ]
    }
   ],
   "source": [
    "# Imports and dependencies\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Module, TripletMarginWithDistanceLoss\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from torcheval.metrics import BinaryAccuracy, BinaryF1Score\n",
    "\n",
    "from src.torch_utils import get_torch_device\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Union, Tuple\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from math import exp\n",
    "\n",
    "TORCH_DEVICE = get_torch_device()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ClaimEvidencePair:\n",
    "    claim_id:str\n",
    "    evidence_id:str\n",
    "    label:int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ClaimEvidenceTriple:\n",
    "    claim_id:str\n",
    "    pos_evidence_id:str\n",
    "    neg_evidence_id:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseEvalDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dev_claims_path:Path,\n",
    "        evidence_path:Path,\n",
    "        device = None,\n",
    "        verbose:bool=True\n",
    "    ) -> None:\n",
    "        super(SiameseEvalDataset, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        self.device = device\n",
    "        \n",
    "        # Load claims data from json\n",
    "        with open(dev_claims_path, mode=\"r\") as f:\n",
    "            self.claims = (json.load(fp=f))\n",
    "\n",
    "        # Load evidence library\n",
    "        self.evidence = dict()\n",
    "        with open(evidence_path, mode=\"r\") as f:\n",
    "            self.evidence.update(json.load(fp=f))\n",
    "        \n",
    "        # Get a list of all evidences within the dev set\n",
    "        self.related_evidences = sorted({\n",
    "            evidence_id\n",
    "            for claim in self.claims.values()\n",
    "            for evidence_id in claim[\"evidences\"]\n",
    "        })\n",
    "        \n",
    "        # Generate the data\n",
    "        self.data = self.__generate_data()\n",
    "        return\n",
    "        \n",
    "    def __generate_data(self):\n",
    "        data = []\n",
    "        for claim_id, claim in tqdm(\n",
    "            iterable=self.claims.items(),\n",
    "            desc=\"claims\",\n",
    "            disable=not self.verbose\n",
    "        ):\n",
    "            evidence_ids = claim[\"evidences\"]\n",
    "            \n",
    "            # Get the positives\n",
    "            for evidence_id in evidence_ids:\n",
    "                data.append(ClaimEvidencePair(\n",
    "                    claim_id=claim_id,\n",
    "                    evidence_id=evidence_id,\n",
    "                    label=1\n",
    "                ))\n",
    "            \n",
    "            # Get some negatives\n",
    "            n_neg = 0\n",
    "            for rel_evidence_id in self.related_evidences:\n",
    "                if n_neg >= 10:\n",
    "                    break\n",
    "                if rel_evidence_id in evidence_ids:\n",
    "                    continue\n",
    "                data.append(ClaimEvidencePair(\n",
    "                    claim_id=claim_id,\n",
    "                    evidence_id=rel_evidence_id,\n",
    "                    label=-1\n",
    "                ))\n",
    "                n_neg += 1\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[Union[str, torch.Tensor]]:\n",
    "        # Fetch the required data rows\n",
    "        data = self.data[idx]\n",
    "        \n",
    "        # Get the label\n",
    "        label = torch.tensor(data.label, device=self.device)\n",
    "        \n",
    "        # Get text ids\n",
    "        claim_id = data.claim_id\n",
    "        evidence_id = data.evidence_id\n",
    "        \n",
    "        # Get text\n",
    "        claim_text = self.claims[claim_id][\"claim_text\"]\n",
    "        evidence_text = self.evidence[evidence_id]\n",
    "\n",
    "        return (claim_text, evidence_text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseTripletDataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        claims_paths:List[Path],\n",
    "        claims_shortlist_paths:List[Path],\n",
    "        evidence_path:Path,\n",
    "        evidence_shortlists:List[Path] = None,\n",
    "        device = None,\n",
    "        n_neg_shortlist:int = 10,\n",
    "        n_neg_general:int = 10,\n",
    "        verbose:bool=True\n",
    "    ) -> None:\n",
    "        super(SiameseTripletDataset, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        self.device = device\n",
    "        self.n_neg_shortlist = n_neg_shortlist\n",
    "        self.n_neg_general = n_neg_general\n",
    "\n",
    "        # Load claims data from json, this is a list as we could use\n",
    "        # multiple json files in the same dataset\n",
    "        self.claims = dict()\n",
    "        for json_file in claims_paths:\n",
    "            with open(json_file, mode=\"r\") as f:\n",
    "                self.claims.update(json.load(fp=f))\n",
    "                # print(f\"loaded claims: {json_file}\")\n",
    "        \n",
    "        # Load the pre-retrieved shortlist of evidences by claim\n",
    "        self.claims_shortlist = dict()\n",
    "        for json_file in claims_shortlist_paths:\n",
    "            with open(json_file, mode=\"r\") as f:\n",
    "                self.claims_shortlist.update(json.load(fp=f))\n",
    "                # print(f\"loaded claims_shortlist: {json_file}\")\n",
    "        \n",
    "        # Load evidence library\n",
    "        self.evidence = dict()\n",
    "        with open(evidence_path, mode=\"r\") as f:\n",
    "            self.evidence.update(json.load(fp=f))\n",
    "            # print(f\"loaded evidences: {json_file}\")\n",
    "        \n",
    "        # Load the evidence shortlists if available\n",
    "        # Reduce the overall evidence list to the shortlist\n",
    "        if evidence_shortlists is not None:\n",
    "            self.evidence_shortlist = set()\n",
    "            for json_file in evidence_shortlists:\n",
    "                with open(json_file, mode=\"r\") as f:\n",
    "                    self.evidence_shortlist.update(json.load(fp=f))\n",
    "                    # print(f\"loaded evidence shortlist: {json_file}\")\n",
    "        \n",
    "        # print(f\"n_evidences: {len(self.evidence)}\")\n",
    "        \n",
    "        # Generate the data\n",
    "        self.data = self.__generate_data()\n",
    "        return\n",
    "\n",
    "    def __generate_data(self):\n",
    "        print(\"Generate siamese dataset\")\n",
    "        \n",
    "        data = []\n",
    "        for claim_id, claim in tqdm(\n",
    "            iterable=self.claims.items(),\n",
    "            desc=\"claims\",\n",
    "            disable=not self.verbose\n",
    "        ):\n",
    "            pos_evidence_ids = set(claim[\"evidences\"])\n",
    "            shortlist_neg_evidence_ids = \\\n",
    "                set(self.claims_shortlist.get(claim_id, [])) \\\n",
    "                .difference(pos_evidence_ids)\n",
    "            general_neg_evidence_ids = self.evidence_shortlist\n",
    "            \n",
    "            # For each positive evidence\n",
    "            for pos_evidence_id in pos_evidence_ids:\n",
    "                \n",
    "                # Add i number of negatives from shortlisted evidences\n",
    "                for i in range(self.n_neg_shortlist):\n",
    "                    if len(shortlist_neg_evidence_ids) > 0:\n",
    "                        neg_evidence_ids = random.sample(\n",
    "                            population=shortlist_neg_evidence_ids,\n",
    "                            k=min(\n",
    "                                self.n_neg_shortlist,\n",
    "                                len(shortlist_neg_evidence_ids)\n",
    "                            )\n",
    "                        )\n",
    "                        \n",
    "                        for neg_evidence_id in neg_evidence_ids:\n",
    "                            data.append(ClaimEvidenceTriple(\n",
    "                                claim_id=claim_id,\n",
    "                                pos_evidence_id=pos_evidence_id,\n",
    "                                neg_evidence_id=neg_evidence_id\n",
    "                            ))\n",
    "                \n",
    "                # Add j number of negatives from general evidences\n",
    "                for j in range(self.n_neg_general):\n",
    "                    neg_evidence_ids = random.sample(\n",
    "                        population=general_neg_evidence_ids,\n",
    "                        k=min(self.n_neg_general, len(general_neg_evidence_ids))\n",
    "                    )\n",
    "                    \n",
    "                    for neg_evidence_id in neg_evidence_ids:\n",
    "                        data.append(ClaimEvidenceTriple(\n",
    "                            claim_id=claim_id,\n",
    "                            pos_evidence_id=pos_evidence_id,\n",
    "                            neg_evidence_id=neg_evidence_id\n",
    "                        ))\n",
    "            continue\n",
    "        \n",
    "        print(f\"Generated data n={len(data)}\")\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[str]:\n",
    "        # Fetch the required data rows\n",
    "        data = self.data[idx]\n",
    "        \n",
    "        # Get text\n",
    "        anchor_text = self.claims[data.claim_id][\"claim_text\"]\n",
    "        pos_evidence_text = self.evidence[data.pos_evidence_id]\n",
    "        neg_evidence_text = self.evidence[data.neg_evidence_id]\n",
    "\n",
    "        return (anchor_text, pos_evidence_text, neg_evidence_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE WILL GENERATE THE DATASET PER EPOCH SO TO RANDOMISE THE NEGATIVE SAMPLES\n",
    "\n",
    "# train_data = SiameseTripletDataset(\n",
    "#     claims_paths=[DATA_PATH.with_name(\"train-claims.json\")],\n",
    "#     claims_shortlist_paths=[NER_PATH.with_name(\"train_claim_evidence_retrieved.json\")],\n",
    "#     evidence_shortlists=[NER_PATH.with_name(\"shortlist_train_claim_evidence_retrieved.json\")],\n",
    "#     evidence_path=DATA_PATH.with_name(\"evidence.json\"),\n",
    "#     device=TORCH_DEVICE,\n",
    "#     n_neg_shortlist=2,\n",
    "#     n_neg_general=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50):\n",
    "#     anchor, pos, neg = train_data[i]\n",
    "#     print(anchor[:50], pos[:50], neg[:50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseTripletEmbedderBert(Module):\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            pretrained_name:str,\n",
    "            device,\n",
    "            **kwargs\n",
    "        ) -> None:\n",
    "        super(SiameseTripletEmbedderBert, self).__init__(**kwargs)\n",
    "        self.device = device\n",
    "        \n",
    "        # Use a pretrained tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_name)\n",
    "        \n",
    "        # Use a pretrained model\n",
    "        self.bert = BertModel.from_pretrained(pretrained_name)\n",
    "        self.bert.to(device=device)\n",
    "        return\n",
    "        \n",
    "    def forward(self, anchor_texts, pos_texts, neg_texts=None) -> Tuple[torch.Tensor]:\n",
    "        \n",
    "        # Run the tokenizer\n",
    "        t_kwargs = {\n",
    "            \"return_tensors\": \"pt\",\n",
    "            \"padding\": True,\n",
    "            \"truncation\": True,\n",
    "            \"max_length\": 100,\n",
    "            \"add_special_tokens\":True\n",
    "        }\n",
    "        anchor_x = self.tokenizer(anchor_texts, **t_kwargs)\n",
    "        pos_x = self.tokenizer(pos_texts, **t_kwargs)\n",
    "        if neg_texts:\n",
    "            neg_x = self.tokenizer(neg_texts, **t_kwargs)\n",
    "        \n",
    "        anchor_x = anchor_x[\"input_ids\"].to(device=self.device)\n",
    "        pos_x = pos_x[\"input_ids\"].to(device=self.device)\n",
    "        if neg_texts:\n",
    "            neg_x = neg_x[\"input_ids\"].to(device=self.device)\n",
    "        \n",
    "        # Run Bert\n",
    "        anchor_x = self.bert(anchor_x, return_dict=True).pooler_output\n",
    "        pos_x = self.bert(pos_x, return_dict=True).pooler_output\n",
    "        if neg_texts:\n",
    "            neg_x = self.bert(neg_x, return_dict=True).pooler_output\n",
    "        # dim=768\n",
    "        \n",
    "        if neg_texts:\n",
    "            return anchor_x, pos_x, neg_x\n",
    "        else:\n",
    "            return anchor_x, pos_x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SiameseTripletEmbedderBert(\n",
    "    pretrained_name=\"bert-base-cased\",\n",
    "    device=TORCH_DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = TripletMarginWithDistanceLoss(\n",
    "    # distance_function=torch.cdist, # Euclidean distance, not implemented for MPS\n",
    "    # Default is Pairwise Distance\n",
    "    margin=2\n",
    ")\n",
    "optimizer = Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=0.0000002\n",
    ") #! Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time = datetime.now().strftime('%Y_%m_%d_%H_%M')\n",
    "MODEL_NAME = f\"model_03a_bert_base_triplet_{run_time}.pth\"\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 195201.82it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_data = SiameseEvalDataset(\n",
    "    dev_claims_path=DATA_PATH.with_name(\"dev-claims.json\"),\n",
    "    evidence_path=DATA_PATH.with_name(\"evidence.json\"),\n",
    "    device=TORCH_DEVICE\n",
    ")\n",
    "\n",
    "dev_dataloader = DataLoader(\n",
    "    dataset=dev_data,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 32/32 [00:09<00:00,  3.55it/s, pos cos_sim: 0.972 neg cos_sim: 0.868]\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation before training to establish baseline\n",
    "model.eval()\n",
    "\n",
    "dev_batches = tqdm(dev_dataloader, desc=\"dev batches\")\n",
    "epoch_pos_cos_sim = []\n",
    "epoch_neg_cos_sim = []\n",
    "for batch in dev_batches:\n",
    "    claim_texts, evidence_texts, labels = batch\n",
    "    \n",
    "    # Forward\n",
    "    claim_emb, evidence_emb = model(claim_texts, evidence_texts)\n",
    "    \n",
    "    # Cosine similarity\n",
    "    cos_sim = torch.cosine_similarity(claim_emb, evidence_emb)\n",
    "    labelled_cos_sim = cos_sim * labels\n",
    "    pos_cos_sim = labelled_cos_sim[torch.where(labelled_cos_sim > 0)]\n",
    "    neg_cos_sim = labelled_cos_sim[torch.where(labelled_cos_sim < 0)]\n",
    "    \n",
    "    batch_pos_cos_sim = torch.mean(pos_cos_sim).cpu().item()\n",
    "    batch_neg_cos_sim = torch.mean(neg_cos_sim).cpu().item() * -1\n",
    "    \n",
    "    epoch_pos_cos_sim.append(batch_pos_cos_sim)\n",
    "    epoch_neg_cos_sim.append(batch_neg_cos_sim)\n",
    "    \n",
    "    dev_batches.postfix = f\"pos cos_sim: {batch_pos_cos_sim:.3f}\" + \\\n",
    "        f\" neg cos_sim: {batch_neg_cos_sim:.3f}\"\n",
    "    \n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cos sim (pos, neg): 0.863419, 0.838396\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average cos sim (pos, neg): {np.mean(epoch_pos_cos_sim):3f}, {np.mean(epoch_neg_cos_sim):3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-08.\n",
      "Epoch: 0 of 10\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:23<00:00, 51.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=102402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 1601/1601 [35:45<00:00,  1.34s/it, loss: 4.260] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.8125e-08.\n",
      "Average epoch loss: 7.312220301500043\n",
      "Saved model to: /Users/johnsonzhou/git/comp90042-project/result/models/model_03a_bert_base_triplet_2023_05_04_07_08.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 32/32 [00:07<00:00,  4.16it/s, pos cos_sim: 0.981 neg cos_sim: 0.968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cos sim (pos, neg): 0.961867, 0.960008\n",
      "Epoch: 1 of 10\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:23<00:00, 52.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=102402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 1601/1601 [35:53<00:00,  1.35s/it, loss: 0.366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.6250e-08.\n",
      "Average epoch loss: 5.077474236488342\n",
      "Saved model to: /Users/johnsonzhou/git/comp90042-project/result/models/model_03a_bert_base_triplet_2023_05_04_07_08.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 32/32 [00:07<00:00,  4.13it/s, pos cos_sim: 0.982 neg cos_sim: 0.976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cos sim (pos, neg): 0.976924, 0.970769\n",
      "Epoch: 2 of 10\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:23<00:00, 52.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=102402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 1601/1601 [36:00<00:00,  1.35s/it, loss: 5.545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0437e-07.\n",
      "Average epoch loss: 3.1247903037115905\n",
      "Saved model to: /Users/johnsonzhou/git/comp90042-project/result/models/model_03a_bert_base_triplet_2023_05_04_07_08.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 32/32 [00:07<00:00,  4.05it/s, pos cos_sim: 0.975 neg cos_sim: 0.966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cos sim (pos, neg): 0.975957, 0.961432\n",
      "Epoch: 3 of 10\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:25<00:00, 49.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=102402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 1601/1601 [35:24<00:00,  1.33s/it, loss: 1.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.3250e-07.\n",
      "Average epoch loss: 2.304878095233537\n",
      "Saved model to: /Users/johnsonzhou/git/comp90042-project/result/models/model_03a_bert_base_triplet_2023_05_04_07_08.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 32/32 [00:07<00:00,  4.11it/s, pos cos_sim: 0.971 neg cos_sim: 0.956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cos sim (pos, neg): 0.973609, 0.950006\n",
      "Epoch: 4 of 10\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:25<00:00, 48.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=102402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 1601/1601 [35:32<00:00,  1.33s/it, loss: 2.753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.6062e-07.\n",
      "Average epoch loss: 1.9718570544766605\n",
      "Saved model to: /Users/johnsonzhou/git/comp90042-project/result/models/model_03a_bert_base_triplet_2023_05_04_07_08.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 32/32 [00:08<00:00,  3.93it/s, pos cos_sim: 0.968 neg cos_sim: 0.952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cos sim (pos, neg): 0.972987, 0.945812\n",
      "Epoch: 5 of 10\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:28<00:00, 42.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=102402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 1601/1601 [36:25<00:00,  1.37s/it, loss: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.8875e-07.\n",
      "Average epoch loss: 1.655956586363314\n",
      "Saved model to: /Users/johnsonzhou/git/comp90042-project/result/models/model_03a_bert_base_triplet_2023_05_04_07_08.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 32/32 [00:07<00:00,  4.06it/s, pos cos_sim: 0.965 neg cos_sim: 0.947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cos sim (pos, neg): 0.971302, 0.941882\n",
      "Epoch: 6 of 10\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:24<00:00, 49.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=102402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 1601/1601 [35:39<00:00,  1.34s/it, loss: 3.492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.8875e-07.\n",
      "Average epoch loss: 1.4308717301409741\n",
      "Saved model to: /Users/johnsonzhou/git/comp90042-project/result/models/model_03a_bert_base_triplet_2023_05_04_07_08.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 32/32 [00:07<00:00,  4.12it/s, pos cos_sim: 0.958 neg cos_sim: 0.940]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cos sim (pos, neg): 0.967719, 0.934870\n",
      "Epoch: 7 of 10\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:25<00:00, 48.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=102402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 1601/1601 [35:33<00:00,  1.33s/it, loss: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.8875e-07.\n",
      "Average epoch loss: 1.2294666864987762\n",
      "Saved model to: /Users/johnsonzhou/git/comp90042-project/result/models/model_03a_bert_base_triplet_2023_05_04_07_08.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 32/32 [00:07<00:00,  4.03it/s, pos cos_sim: 0.951 neg cos_sim: 0.928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cos sim (pos, neg): 0.963640, 0.924704\n",
      "Epoch: 8 of 10\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:25<00:00, 48.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=102402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 1601/1601 [35:39<00:00,  1.34s/it, loss: 3.047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.8875e-07.\n",
      "Average epoch loss: 1.0845261827427697\n",
      "Saved model to: /Users/johnsonzhou/git/comp90042-project/result/models/model_03a_bert_base_triplet_2023_05_04_07_08.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 32/32 [00:07<00:00,  4.21it/s, pos cos_sim: 0.947 neg cos_sim: 0.920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cos sim (pos, neg): 0.960711, 0.916577\n",
      "Epoch: 9 of 10\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:25<00:00, 48.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=102402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 1601/1601 [35:27<00:00,  1.33s/it, loss: 0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.8875e-07.\n",
      "Average epoch loss: 0.9524464424255116\n",
      "Saved model to: /Users/johnsonzhou/git/comp90042-project/result/models/model_03a_bert_base_triplet_2023_05_04_07_08.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 32/32 [00:07<00:00,  4.22it/s, pos cos_sim: 0.940 neg cos_sim: 0.910]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cos sim (pos, neg): 0.957843, 0.909097\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metric_accuracy = BinaryAccuracy()\n",
    "metric_f1 = BinaryF1Score()\n",
    "metric_recall = BinaryF1Score()\n",
    "\n",
    "scheduler = LinearLR(\n",
    "    optimizer=optimizer,\n",
    "    start_factor=0.1,\n",
    "    end_factor=1,\n",
    "    total_iters=BATCH_SIZE/10,\n",
    "    verbose=True\n",
    ")\n",
    "best_epoch_loss = 999\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    print(f\"Epoch: {epoch} of {N_EPOCHS}\\n\")\n",
    "    \n",
    "    # Run training\n",
    "    model.train()\n",
    "    \n",
    "    train_data = SiameseTripletDataset(\n",
    "        claims_paths=[DATA_PATH.with_name(\"train-claims.json\")],\n",
    "        claims_shortlist_paths=[NER_PATH.with_name(\"train_claim_evidence_retrieved.json\")],\n",
    "        evidence_shortlists=[NER_PATH.with_name(\"shortlist_train_claim_evidence_retrieved.json\")],\n",
    "        evidence_path=DATA_PATH.with_name(\"evidence.json\"),\n",
    "        device=TORCH_DEVICE,\n",
    "        n_neg_shortlist=5,\n",
    "        n_neg_general=1\n",
    "    )\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        shuffle=True,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    train_batches = tqdm(train_dataloader, desc=\"train batches\")\n",
    "    running_losses = []\n",
    "    for batch in train_batches:\n",
    "        anchor, positive, negative = batch\n",
    "        \n",
    "        # Reset optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward + loss\n",
    "        anchor_emb, pos_emb, neg_emb = model(anchor, positive, negative)\n",
    "        loss = loss_fn(anchor=anchor_emb, positive=pos_emb, negative=neg_emb)\n",
    "        \n",
    "        # Backward + optimiser\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update running loss\n",
    "        batch_loss = loss.item() * len(batch)\n",
    "        running_losses.append(batch_loss)\n",
    "        \n",
    "        train_batches.postfix = f\"loss: {batch_loss:.3f}\"\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    epoch_loss = np.average(running_losses)\n",
    "    print(f\"Average epoch loss: {epoch_loss}\")\n",
    "    \n",
    "    # Save model\n",
    "    if epoch_loss <= best_epoch_loss:\n",
    "        best_epoch_loss = epoch_loss\n",
    "        torch.save(model, MODEL_PATH.with_name(MODEL_NAME))\n",
    "        print(f\"Saved model to: {MODEL_PATH.with_name(MODEL_NAME)}\")\n",
    "    \n",
    "    # Evaluate every 5 epochs\n",
    "    # if epoch % 5 != 0:\n",
    "    #     continue\n",
    "    \n",
    "    # Run evaluation before training to establish baseline\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    dev_batches = tqdm(dev_dataloader, desc=\"dev batches\")\n",
    "    epoch_pos_cos_sim = []\n",
    "    epoch_neg_cos_sim = []\n",
    "    for batch in dev_batches:\n",
    "        claim_texts, evidence_texts, labels = batch\n",
    "\n",
    "        # Forward\n",
    "        claim_emb, evidence_emb = model(claim_texts, evidence_texts)\n",
    "\n",
    "        # Cosine similarity\n",
    "        cos_sim = torch.cosine_similarity(claim_emb, evidence_emb)\n",
    "        labelled_cos_sim = cos_sim * labels\n",
    "        pos_cos_sim = labelled_cos_sim[torch.where(labelled_cos_sim > 0)]\n",
    "        neg_cos_sim = labelled_cos_sim[torch.where(labelled_cos_sim < 0)]\n",
    "\n",
    "        batch_pos_cos_sim = torch.mean(pos_cos_sim).cpu().item()\n",
    "        batch_neg_cos_sim = torch.mean(neg_cos_sim).cpu().item() * -1\n",
    "\n",
    "        epoch_pos_cos_sim.append(batch_pos_cos_sim)\n",
    "        epoch_neg_cos_sim.append(batch_neg_cos_sim)\n",
    "\n",
    "        dev_batches.postfix = f\"pos cos_sim: {batch_pos_cos_sim:.3f}\" + \\\n",
    "            f\" neg cos_sim: {batch_neg_cos_sim:.3f}\"\n",
    "\n",
    "        continue\n",
    "    \n",
    "    print(f\"Average cos sim (pos, neg): {np.mean(epoch_pos_cos_sim):3f}, {np.mean(epoch_neg_cos_sim):3f}\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SentenceSimilarity:\n",
    "    label:int\n",
    "    score:float\n",
    "    claim_text:str\n",
    "    evidence_text:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 32/32 [00:07<00:00,  4.32it/s, pos cos_sim: 0.940 neg cos_sim: 0.910]\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation before training to establish baseline\n",
    "model.eval()\n",
    "\n",
    "dev_batches = tqdm(dev_dataloader, desc=\"dev batches\")\n",
    "epoch_pos_cos_sim = []\n",
    "epoch_neg_cos_sim = []\n",
    "sentence_rankings = []\n",
    "sentence_rankings_dot = []\n",
    "for batch in dev_batches:\n",
    "    claim_texts, evidence_texts, labels = batch\n",
    "    \n",
    "    # Forward\n",
    "    claim_emb, evidence_emb = model(claim_texts, evidence_texts)\n",
    "    \n",
    "    # Cosine similarity\n",
    "    cos_sim = torch.cosine_similarity(claim_emb, evidence_emb)\n",
    "    labelled_cos_sim = cos_sim * labels\n",
    "    pos_cos_sim = labelled_cos_sim[torch.where(labelled_cos_sim > 0)]\n",
    "    neg_cos_sim = labelled_cos_sim[torch.where(labelled_cos_sim < 0)]\n",
    "    \n",
    "    batch_pos_cos_sim = torch.mean(pos_cos_sim).cpu().item()\n",
    "    batch_neg_cos_sim = torch.mean(neg_cos_sim).cpu().item() * -1\n",
    "    \n",
    "    epoch_pos_cos_sim.append(batch_pos_cos_sim)\n",
    "    epoch_neg_cos_sim.append(batch_neg_cos_sim)\n",
    "    \n",
    "    for claim_text, evidence_text, label, score in \\\n",
    "        zip(\n",
    "            claim_texts, evidence_texts, \n",
    "            labels.detach().cpu().numpy(), cos_sim.detach().cpu().numpy()\n",
    "        ):\n",
    "        sentence_rankings.append(SentenceSimilarity(\n",
    "            label=label,\n",
    "            score=score,\n",
    "            claim_text=claim_text,\n",
    "            evidence_text=evidence_text\n",
    "        ))\n",
    "    \n",
    "    dev_batches.postfix = f\"pos cos_sim: {batch_pos_cos_sim:.3f}\" + \\\n",
    "        f\" neg cos_sim: {batch_neg_cos_sim:.3f}\"\n",
    "    \n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cos sim (pos, neg): 0.957843, 0.909097\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average cos sim (pos, neg): {np.mean(epoch_pos_cos_sim):3f}, {np.mean(epoch_neg_cos_sim):3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentenceSimilarity(label=1, score=0.9862933, claim_text='[South Australia] has the most expensive electricity in the world.', evidence_text='[citation needed] South Australia has the highest retail price for electricity in the country.'),\n",
       " SentenceSimilarity(label=1, score=0.9728399, claim_text='[South Australia] has the most expensive electricity in the world.', evidence_text='\"South Australia has the highest power prices in the world\".'),\n",
       " SentenceSimilarity(label=-1, score=0.88018227, claim_text='[South Australia] has the most expensive electricity in the world.', evidence_text='\"How the oceans absorb carbon dioxide is critical for predicting climate change\".'),\n",
       " SentenceSimilarity(label=-1, score=0.91277826, claim_text='[South Australia] has the most expensive electricity in the world.', evidence_text='Families are forced into increasing poverty, some facing a daily struggle to pay their rent and put food on their table.'),\n",
       " SentenceSimilarity(label=-1, score=0.94074315, claim_text='[South Australia] has the most expensive electricity in the world.', evidence_text='They described the intermediate scenario as the most likely, and that real-world greenhouse gas forcing had been closest to this scenario.'),\n",
       " SentenceSimilarity(label=-1, score=0.9158981, claim_text='[South Australia] has the most expensive electricity in the world.', evidence_text='Absorption of infrared light at the vibrational frequencies of atmospheric carbon dioxide traps energy near the surface, warming the surface and the lower atmosphere.'),\n",
       " SentenceSimilarity(label=-1, score=0.9338268, claim_text='[South Australia] has the most expensive electricity in the world.', evidence_text='Scientists Reach 100% Consensus on Anthropogenic Global Warming.'),\n",
       " SentenceSimilarity(label=-1, score=0.9055586, claim_text='[South Australia] has the most expensive electricity in the world.', evidence_text='The Labour Party proposed a renegotiation of the withdrawal agreement (towards a closer post-withdrawal relationship with the EU) and would then put this forward as an option in a referendum alongside the option of remaining in the EU.'),\n",
       " SentenceSimilarity(label=-1, score=0.932196, claim_text='[South Australia] has the most expensive electricity in the world.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.9631871, claim_text='[South Australia] has the most expensive electricity in the world.', evidence_text='The 2007 melt season let to a minimum 39% below the 1979–2000 average, and for the first time in human memory, the fabled Northwest Passage opened completely.'),\n",
       " SentenceSimilarity(label=-1, score=0.92790437, claim_text='[South Australia] has the most expensive electricity in the world.', evidence_text='Surface heat and freshwater fluxes create global density gradients that drive the thermohaline circulation part of large-scale ocean circulation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9159003, claim_text='[South Australia] has the most expensive electricity in the world.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=1, score=0.96071076, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='The 2011 UNEP Green Economy report states that \"[a]agricultural operations, excluding land use changes, produce approximately 13 per cent of anthropogenic global GHG emissions.'),\n",
       " SentenceSimilarity(label=1, score=0.9581753, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='With a market share of 30% and (potentially) clean electricity, heat pumps could reduce global CO 2 emissions by 8% annually.'),\n",
       " SentenceSimilarity(label=1, score=0.90357435, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='In the modern era, emissions to the atmosphere from volcanoes are approximately 0.645 billion tonnes of CO 2 per year, whereas humans contribute 29 billion tonnes of CO 2 each year.'),\n",
       " SentenceSimilarity(label=1, score=0.98386014, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='Cumulative anthropogenic (i.e., human-emitted) emissions of CO 2 from fossil fuel use are a major cause of global warming, and give some indication of which countries have contributed most to human-induced climate change.'),\n",
       " SentenceSimilarity(label=1, score=0.9833344, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='Other countries with fast growing emissions are South Korea, Iran, and Australia (which apart from the oil rich Persian Gulf states, now has the highest percapita emission rate in the world).'),\n",
       " SentenceSimilarity(label=-1, score=0.9186387, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='\"How the oceans absorb carbon dioxide is critical for predicting climate change\".'),\n",
       " SentenceSimilarity(label=-1, score=0.898131, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='Families are forced into increasing poverty, some facing a daily struggle to pay their rent and put food on their table.'),\n",
       " SentenceSimilarity(label=-1, score=0.96306026, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='They described the intermediate scenario as the most likely, and that real-world greenhouse gas forcing had been closest to this scenario.'),\n",
       " SentenceSimilarity(label=-1, score=0.92450315, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='Absorption of infrared light at the vibrational frequencies of atmospheric carbon dioxide traps energy near the surface, warming the surface and the lower atmosphere.'),\n",
       " SentenceSimilarity(label=-1, score=0.96233195, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='Scientists Reach 100% Consensus on Anthropogenic Global Warming.'),\n",
       " SentenceSimilarity(label=-1, score=0.9226153, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='The Labour Party proposed a renegotiation of the withdrawal agreement (towards a closer post-withdrawal relationship with the EU) and would then put this forward as an option in a referendum alongside the option of remaining in the EU.'),\n",
       " SentenceSimilarity(label=-1, score=0.9552816, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.95446944, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='The 2007 melt season let to a minimum 39% below the 1979–2000 average, and for the first time in human memory, the fabled Northwest Passage opened completely.'),\n",
       " SentenceSimilarity(label=-1, score=0.9291469, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='Surface heat and freshwater fluxes create global density gradients that drive the thermohaline circulation part of large-scale ocean circulation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9415269, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=1, score=0.97985446, claim_text='This means that the world is now 1C warmer than it was in pre-industrial times', evidence_text='Multiple independently produced instrumental datasets confirm that the 2009–2018 decade was 0.93 ± 0.07\\xa0°C warmer than the pre-industrial baseline (1850–1900).'),\n",
       " SentenceSimilarity(label=1, score=0.9973033, claim_text='This means that the world is now 1C warmer than it was in pre-industrial times', evidence_text='The planet is now 0.8\\xa0°C warmer than in pre-industrial times.'),\n",
       " SentenceSimilarity(label=-1, score=0.93215805, claim_text='This means that the world is now 1C warmer than it was in pre-industrial times', evidence_text='\"How the oceans absorb carbon dioxide is critical for predicting climate change\".'),\n",
       " SentenceSimilarity(label=-1, score=0.7381977, claim_text='This means that the world is now 1C warmer than it was in pre-industrial times', evidence_text='Families are forced into increasing poverty, some facing a daily struggle to pay their rent and put food on their table.'),\n",
       " SentenceSimilarity(label=-1, score=0.88814014, claim_text='This means that the world is now 1C warmer than it was in pre-industrial times', evidence_text='They described the intermediate scenario as the most likely, and that real-world greenhouse gas forcing had been closest to this scenario.'),\n",
       " SentenceSimilarity(label=-1, score=0.9234582, claim_text='This means that the world is now 1C warmer than it was in pre-industrial times', evidence_text='Absorption of infrared light at the vibrational frequencies of atmospheric carbon dioxide traps energy near the surface, warming the surface and the lower atmosphere.'),\n",
       " SentenceSimilarity(label=-1, score=0.9140771, claim_text='This means that the world is now 1C warmer than it was in pre-industrial times', evidence_text='Scientists Reach 100% Consensus on Anthropogenic Global Warming.'),\n",
       " SentenceSimilarity(label=-1, score=0.7366704, claim_text='This means that the world is now 1C warmer than it was in pre-industrial times', evidence_text='The Labour Party proposed a renegotiation of the withdrawal agreement (towards a closer post-withdrawal relationship with the EU) and would then put this forward as an option in a referendum alongside the option of remaining in the EU.'),\n",
       " SentenceSimilarity(label=-1, score=0.9508436, claim_text='This means that the world is now 1C warmer than it was in pre-industrial times', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.94015294, claim_text='This means that the world is now 1C warmer than it was in pre-industrial times', evidence_text='The 2007 melt season let to a minimum 39% below the 1979–2000 average, and for the first time in human memory, the fabled Northwest Passage opened completely.'),\n",
       " SentenceSimilarity(label=-1, score=0.91707116, claim_text='This means that the world is now 1C warmer than it was in pre-industrial times', evidence_text='Surface heat and freshwater fluxes create global density gradients that drive the thermohaline circulation part of large-scale ocean circulation.'),\n",
       " SentenceSimilarity(label=-1, score=0.95023346, claim_text='This means that the world is now 1C warmer than it was in pre-industrial times', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=1, score=0.9462719, claim_text='“As it happens, Zika may also be a good model of the second worrying effect — disease mutation.', evidence_text='Genetic disorders are the result of deleterious mutations and can be due to spontaneous mutation in the affected individual, or can be inherited.'),\n",
       " SentenceSimilarity(label=1, score=0.9687269, claim_text='“As it happens, Zika may also be a good model of the second worrying effect — disease mutation.', evidence_text='These errors, called mutations, can affect the phenotype of an organism, especially if they occur within the protein coding sequence of a gene.'),\n",
       " SentenceSimilarity(label=1, score=0.97977304, claim_text='“As it happens, Zika may also be a good model of the second worrying effect — disease mutation.', evidence_text='This is especially useful studying diseases in adults by allowing expression after a certain period of growth, thus eliminating the deleterious effect of gene expression seen during stages of development in model organisms.'),\n",
       " SentenceSimilarity(label=1, score=0.9864032, claim_text='“As it happens, Zika may also be a good model of the second worrying effect — disease mutation.', evidence_text='In addition, research was needed to determine the mechanism by which Zika produced these effects.'),\n",
       " SentenceSimilarity(label=1, score=0.9712744, claim_text='“As it happens, Zika may also be a good model of the second worrying effect — disease mutation.', evidence_text='Zika also appears to have an equal tropism for cells of the developing eye, leading to high rates of eye abnormalities as well.'),\n",
       " SentenceSimilarity(label=-1, score=0.89165485, claim_text='“As it happens, Zika may also be a good model of the second worrying effect — disease mutation.', evidence_text='\"How the oceans absorb carbon dioxide is critical for predicting climate change\".'),\n",
       " SentenceSimilarity(label=-1, score=0.9021528, claim_text='“As it happens, Zika may also be a good model of the second worrying effect — disease mutation.', evidence_text='Families are forced into increasing poverty, some facing a daily struggle to pay their rent and put food on their table.'),\n",
       " SentenceSimilarity(label=-1, score=0.97374755, claim_text='“As it happens, Zika may also be a good model of the second worrying effect — disease mutation.', evidence_text='They described the intermediate scenario as the most likely, and that real-world greenhouse gas forcing had been closest to this scenario.'),\n",
       " SentenceSimilarity(label=-1, score=0.9138335, claim_text='“As it happens, Zika may also be a good model of the second worrying effect — disease mutation.', evidence_text='Absorption of infrared light at the vibrational frequencies of atmospheric carbon dioxide traps energy near the surface, warming the surface and the lower atmosphere.'),\n",
       " SentenceSimilarity(label=-1, score=0.9286028, claim_text='“As it happens, Zika may also be a good model of the second worrying effect — disease mutation.', evidence_text='Scientists Reach 100% Consensus on Anthropogenic Global Warming.'),\n",
       " SentenceSimilarity(label=-1, score=0.91616154, claim_text='“As it happens, Zika may also be a good model of the second worrying effect — disease mutation.', evidence_text='The Labour Party proposed a renegotiation of the withdrawal agreement (towards a closer post-withdrawal relationship with the EU) and would then put this forward as an option in a referendum alongside the option of remaining in the EU.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_rankings[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sentence_rankings = sorted([\n",
    "    s for s in sentence_rankings\n",
    "    if s.label == 1\n",
    "], key=lambda s: s.score)\n",
    "\n",
    "neg_sentence_rankings = sorted([\n",
    "    s for s in sentence_rankings\n",
    "    if s.label == -1\n",
    "], key=lambda s: s.score, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentenceSimilarity(label=1, score=0.7421593, claim_text='The unlikely scenarios are now, all of a sudden, becoming more probable than they once were thought to be,’ says Sweet.”', evidence_text='The reverse possibility, that a small group broke off and wandered from India into Western Asia is readily dismissed as an improbably long migration, again without the least bit of evidence.'),\n",
       " SentenceSimilarity(label=1, score=0.8128866, claim_text='The unlikely scenarios are now, all of a sudden, becoming more probable than they once were thought to be,’ says Sweet.”', evidence_text=\"In recent decades, a few specialists have continued to support this interpretation, and Peter Schrijver has said that 'to a large extent, it is linguistics that is responsible for thinking in terms of drastic scenarios' about demographic change in late Roman Britain.\"),\n",
       " SentenceSimilarity(label=1, score=0.8138266, claim_text='Satellite measurements of infrared spectra over the past 40 years observe less energy escaping to space at the wavelengths associated with CO2.', evidence_text='The three channels use the same frequency but different carbon dioxide cell pressure, the corresponding weighting functions peaks at 29\\xa0km for channel 1, 37\\xa0km for channel 2 and 45\\xa0km for channel 3.'),\n",
       " SentenceSimilarity(label=1, score=0.8338872, claim_text=\"'Another global warming myth comes crashing down.\", evidence_text='The conspiracy behind the Anthropogenic Global Warming myth (aka AGW; aka ManBearPig) has been suddenly, brutally and quite deliciously exposed\", and \"A contretemps with a Climate Bully who wonders whether I have a science degree.'),\n",
       " SentenceSimilarity(label=1, score=0.84104425, claim_text='That’s because as Antarctica’s mass shrinks, the ice sheet’s gravitational pull on the ocean relaxes somewhat, and the seas travel back across the globe to pile up far away — with U.S. coasts being one prime destination.”', evidence_text='With the loss of mass, the gravitational pull becomes less and local water levels might drop.'),\n",
       " SentenceSimilarity(label=1, score=0.8445357, claim_text=\"'Another global warming myth comes crashing down.\", evidence_text='Delingpole has engaged in climate change denialism; in 2009 he wrote of \"The conspiracy behind the Anthropogenic Global Warming myth\".'),\n",
       " SentenceSimilarity(label=1, score=0.8542311, claim_text='Many of the world’s coral reefs are already barren or in a state of constant decline.', evidence_text='Aquaculture is showing promise as a potentially effective tool for restoring coral reefs, which have been declining around the world.'),\n",
       " SentenceSimilarity(label=1, score=0.8606622, claim_text='A 14 August 1912 article from a New Zealand newspaper contained a brief story about how burning coal might produce future warming by adding carbon dioxide to the atmosphere.', evidence_text='The largest and most long term effect of coal use is the release of carbon dioxide, a greenhouse gas that causes climate change and global warming.'),\n",
       " SentenceSimilarity(label=1, score=0.8611027, claim_text='[…] Constant 24-7  media coverage of every significant storm worldwide just makes it seem  that way.”', evidence_text='The severe and widespread damage the storm caused in the United States, as well as its unusual merger with a frontal system, resulted in the nicknaming of the hurricane \"Superstorm Sandy\" by the media, public officials, and several organizations, including U.S. government agencies.'),\n",
       " SentenceSimilarity(label=1, score=0.8648185, claim_text='\"Austria is today seeing its earliest snowfall in history with 30 to 40 centimetres already predicted in the mountains.', evidence_text=\"This law of neutrality, passed in late October 1955 (and not the State Treaty itself), ensured that modern Austria would align with neither NATO nor the Soviet bloc, and is considered one of the reasons for Austria's delayed entry into the European Union in 1995.\"),\n",
       " SentenceSimilarity(label=1, score=0.8670504, claim_text='Concentrated in the atmosphere, these gases do not allow the warmth of the sun’s rays reflected by the earth to be dispersed in space.', evidence_text='Ozone acts as a greenhouse gas, absorbing some of the infrared energy emitted by the earth.'),\n",
       " SentenceSimilarity(label=1, score=0.87138534, claim_text='In the past, warming has never been a threat to life on Earth.', evidence_text='Given the potential threat to marine ecosystems and its ensuing impact on human society and economy, especially as it acts in conjunction with anthropogenic global warming, there is an urgent need for immediate action.\"'),\n",
       " SentenceSimilarity(label=1, score=0.87565756, claim_text='But each serial adjustment has tended to make the early years colder, which increases the warming trend.', evidence_text='Climate change adaptation is \"the adjustment in natural or human systems in response to actual or expected climatic stimuli or their effects, which moderates harm or exploits beneficial opportunities\".'),\n",
       " SentenceSimilarity(label=1, score=0.8821011, claim_text='A 14 August 1912 article from a New Zealand newspaper contained a brief story about how burning coal might produce future warming by adding carbon dioxide to the atmosphere.', evidence_text='Coal production is a major contributor to global warming: burning coal generates large quantities of carbon dioxide and mining operations can release methane, a known greenhouse gas, into the atmosphere.'),\n",
       " SentenceSimilarity(label=1, score=0.8833026, claim_text='\\'To suddenly label CO2 as a \"pollutant\" is a disservice to a gas that has played an enormous role in the development and sustainability of all life on this wonderful Earth.', evidence_text='Emissions trading (also known as cap and trade) is a market-based approach to controlling pollution by providing economic incentives for achieving reductions in the emissions of pollutants.'),\n",
       " SentenceSimilarity(label=1, score=0.8869983, claim_text='\"Each unit of CO2 you put into the atmosphere has less and less of a warming impact.', evidence_text='This creates air pollution, including nitrous oxides and particulates, and is a significant contributor to global warming through emission of carbon dioxide, for which transport is the fastest-growing emission sector.'),\n",
       " SentenceSimilarity(label=1, score=0.8911661, claim_text='\"Each unit of CO2 you put into the atmosphere has less and less of a warming impact.', evidence_text='The international community began the long process towards building effective international and domestic measures to tackle GHG emissions (carbon dioxide, methane, nitrous oxide, hydroflurocarbons, perfluorocarbons, sulphur hexafluoride) in response to the increasing assertions that global warming is happening due to man-made emissions and the uncertainty over its likely consequences.'),\n",
       " SentenceSimilarity(label=1, score=0.89138424, claim_text=\"Al Gore's book is quite accurate, and far more accurate than contrarian books.\", evidence_text='\"He is making a qualitative point, which is entirely accurate.'),\n",
       " SentenceSimilarity(label=1, score=0.8923762, claim_text='‘If we do nothing to reduce our greenhouse gas emissions, the kind of extreme heat we saw this past summer will be the norm when my young son is a grown man.’', evidence_text='Avoiding this future warming will require a large and rapid reduction in global greenhouse gas emissions.'),\n",
       " SentenceSimilarity(label=1, score=0.89385724, claim_text='Jim Hansen had several possible scenarios; his mid-level scenario B was right.', evidence_text='In 2000 Hansen authored a paper called \"Global warming in the twenty-first century: an alternative scenario\" in which he presented a more optimistic way of dealing with global warming, focusing on non-CO2 gases and black carbon in the short run, giving more time to make reductions in fossil fuel emissions.'),\n",
       " SentenceSimilarity(label=1, score=0.89479446, claim_text='Satellite measurements of infrared spectra over the past 40 years observe less energy escaping to space at the wavelengths associated with CO2.', evidence_text='They measure radiances in various wavelength bands.'),\n",
       " SentenceSimilarity(label=1, score=0.89486736, claim_text='Heat is continuing to build up in the subsurface ocean.', evidence_text='It plays an important role in supplying heat to the polar regions, and thus in sea ice regulation.'),\n",
       " SentenceSimilarity(label=1, score=0.896196, claim_text='Many of the world’s coral reefs are already barren or in a state of constant decline.', evidence_text='For example, Midway Atoll in Hawaii supports nearly three million seabirds, including two-thirds (1.5 million) of the global population of Laysan albatross, and one-third of the global population of black-footed albatross.'),\n",
       " SentenceSimilarity(label=1, score=0.8965926, claim_text=\"CO2 limits won't cool the planet.\", evidence_text='Occupational CO 2 exposure limits have been set in the United States at 0.5% (5000 ppm) for an eight-hour period.'),\n",
       " SentenceSimilarity(label=1, score=0.8993787, claim_text='Heat is continuing to build up in the subsurface ocean.', evidence_text='Titan is thought to have a subsurface liquid-water ocean under the ice in addition to the hydrocarbon mix that forms atop its outer crust.'),\n",
       " SentenceSimilarity(label=1, score=0.90181994, claim_text='More importantly, the OISM list only contains 39 scientists who specialise in climate science.', evidence_text='A botanist, plant scientist or phytologist is a scientist who specialises in this field.'),\n",
       " SentenceSimilarity(label=1, score=0.90357435, claim_text='when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\xaduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\xadn here will have any effect on global climate.', evidence_text='In the modern era, emissions to the atmosphere from volcanoes are approximately 0.645 billion tonnes of CO 2 per year, whereas humans contribute 29 billion tonnes of CO 2 each year.'),\n",
       " SentenceSimilarity(label=1, score=0.9065251, claim_text='“Today climate scientists are obsessed with the level of carbon dioxide in the atmosphere, a very very small part of the overall picture.', evidence_text=\"The world's most important greenhouse gas is carbon dioxide, a by-product of the burning of fossil fuels.\"),\n",
       " SentenceSimilarity(label=1, score=0.9076155, claim_text='In the past, warming has never been a threat to life on Earth.', evidence_text='Global warming is a major threat to global biodiversity.'),\n",
       " SentenceSimilarity(label=1, score=0.90870786, claim_text='Many of the world’s coral reefs are already barren or in a state of constant decline.', evidence_text='This can rapidly result in transitions to barren landscapes where relatively few species persist.'),\n",
       " SentenceSimilarity(label=1, score=0.9107156, claim_text=\"Al Gore's book is quite accurate, and far more accurate than contrarian books.\", evidence_text='In a 2007 court case, a British judge said that while he had \"no doubt ...the film was broadly accurate\" and its \"four main scientific hypotheses ...are supported by a vast quantity of research\", he upheld nine of a \"long schedule\" of alleged errors presented to the court.'),\n",
       " SentenceSimilarity(label=1, score=0.9126637, claim_text='[Riebesell] is a world authority on the topic and has typically communicated cautiously about the effects of acidification.', evidence_text='Perhaps one of the most recent adverse effects of climate change to be explored is that of ocean acidification.'),\n",
       " SentenceSimilarity(label=1, score=0.9127861, claim_text='Heat is continuing to build up in the subsurface ocean.', evidence_text='Underneath the thick atmospheres of the planets Uranus and Neptune, it is expected that these planets are composed of oceans of hot high-density fluid mixtures of water, ammonia and other volatiles.'),\n",
       " SentenceSimilarity(label=1, score=0.9135247, claim_text='[Riebesell] is a world authority on the topic and has typically communicated cautiously about the effects of acidification.', evidence_text='Climate change is more accurate scientifically to describe the various effects of greenhouse gases on the world because it includes extreme weather, storms and changes in rainfall patterns, ocean acidification and sea level.\".'),\n",
       " SentenceSimilarity(label=1, score=0.913995, claim_text='Global Warming history completely coincides with the history of artificial satellites and the use of microwave frequencies from outer space.', evidence_text='A communications satellite is an artificial satellite that relays and amplifies radio telecommunications signals via a transponder; it creates a communication channel between a source transmitter and a receiver at different locations on Earth.'),\n",
       " SentenceSimilarity(label=1, score=0.91404426, claim_text='\\'To suddenly label CO2 as a \"pollutant\" is a disservice to a gas that has played an enormous role in the development and sustainability of all life on this wonderful Earth.', evidence_text='In its book, the Commission described four key elements of sustainability with respect to energy: the ability to increase the supply of energy to meet growing human needs, energy efficiency and conservation, public health and safety, and \"protection of the biosphere and prevention of more localized forms of pollution.\"'),\n",
       " SentenceSimilarity(label=1, score=0.91530365, claim_text='“In their award winning book, ‘Taken By Storm’ (2007), Canadian researchers Christopher Essex and Ross McKitrick explain: ‘Temperature is not an amount of something [like height or weight].', evidence_text='Lately, the temperature criterion has fallen out of the definition across the United States Bomb cyclone\\xa0– A rapid deepening of a mid-latitude cyclonic low-pressure area, typically occurring over the ocean, but can occur over land.'),\n",
       " SentenceSimilarity(label=1, score=0.9158899, claim_text=\"Without the forests' humidity, previously moisture-laden winds blew dry.\", evidence_text='An important feature of cloud forests is the tree crowns can intercept the wind-driven cloud moisture, part of which drips to the ground.'),\n",
       " SentenceSimilarity(label=1, score=0.9162524, claim_text='The unlikely scenarios are now, all of a sudden, becoming more probable than they once were thought to be,’ says Sweet.”', evidence_text='Many feasible scenarios can be constructed to account for evidence.'),\n",
       " SentenceSimilarity(label=1, score=0.9173758, claim_text='\"Three recent articles give us reason to question the alarmists’ claims  that coral reefs are in deep trouble due to the buildup of greenhouse  gases.\" (World Climate Report)', evidence_text='Greenhouse gas emissions present a broader threat through sea temperature rise and sea level rise, though corals adapt their calcifying fluids to changes in seawater pH and carbonate levels and are not directly threatened by ocean acidification.'),\n",
       " SentenceSimilarity(label=1, score=0.9184256, claim_text='More importantly, the OISM list only contains 39 scientists who specialise in climate science.', evidence_text='The list includes scientists from several specialities or disciplines.'),\n",
       " SentenceSimilarity(label=1, score=0.91852915, claim_text='The IPCC no longer includes the ‘Hockey stick’ chart in its reports.', evidence_text='A paragraph in the 2007 Working Group II report (\"Impacts, Adaptation and Vulnerability\"), chapter 10 included a projection that Himalayan glaciers could disappear by 2035 Glaciers in the Himalaya are receding faster than in any other part of the world (see Table 10.9) and, if the present rate continues, the likelihood of them disappearing by the year 2035 and perhaps sooner is very high if the Earth keeps warming at the current rate.'),\n",
       " SentenceSimilarity(label=1, score=0.9195077, claim_text='But [climate scientists] say that aspects of the case of Hurricane Harvey—and the recent history of tropical cyclones worldwide—suggest global warming is making a bad situation worse.', evidence_text='\"It\\'s a fact: climate change made Hurricane Harvey more deadly\".'),\n",
       " SentenceSimilarity(label=1, score=0.9200354, claim_text='many scientists were surprised when other researchers subsequently found that ringed and bearded seals (the primary prey of polar bears) north of the Bering Strait especially thrived with a longer open-water season, which is particularly conducive to fishing', evidence_text='Natural predators of the bearded seal include polar bears, who rely on these seals as a major food source.'),\n",
       " SentenceSimilarity(label=1, score=0.920043, claim_text='Reefs need carbon dioxide; it’s their basic food.', evidence_text=\"Ocean acidification is the ongoing decrease in the pH of the Earth's oceans, caused by the uptake of carbon dioxide (CO 2) from the atmosphere.\"),\n",
       " SentenceSimilarity(label=1, score=0.92189467, claim_text='many scientists were surprised when other researchers subsequently found that ringed and bearded seals (the primary prey of polar bears) north of the Bering Strait especially thrived with a longer open-water season, which is particularly conducive to fishing', evidence_text='The polar bear is the most carnivorous member of the bear family, and throughout most of its range, its diet primarily consists of ringed (Pusa hispida) and bearded seals (Erignathus barbatus).'),\n",
       " SentenceSimilarity(label=1, score=0.9221988, claim_text='“In their award winning book, ‘Taken By Storm’ (2007), Canadian researchers Christopher Essex and Ross McKitrick explain: ‘Temperature is not an amount of something [like height or weight].', evidence_text='The most common scales are the Celsius scale (formerly called centigrade), denoted °C, the Fahrenheit scale (denoted °F), and the Kelvin scale (denoted K), the latter of which is predominantly used for scientific purposes by conventions of the International System of Units (SI).'),\n",
       " SentenceSimilarity(label=1, score=0.92231816, claim_text=\"Without the forests' humidity, previously moisture-laden winds blew dry.\", evidence_text='Laurel forest and other cloud forest are subtropical and mild temperate forest, found in areas with high humidity and relatively stable and mild temperatures.'),\n",
       " SentenceSimilarity(label=1, score=0.9226341, claim_text='Satellite measurements of infrared spectra over the past 40 years observe less energy escaping to space at the wavelengths associated with CO2.', evidence_text='Cosmic-temperature measurements The VLT has detected, for the first time, carbon-monoxide molecules in a galaxy located almost 11\\xa0billion light-years away.'),\n",
       " SentenceSimilarity(label=1, score=0.9229605, claim_text='Greenpeace didn’t save the whales, switching from whale oil to petroleum and palm oil did', evidence_text='Another Greenpeace movement concerning the rain forests is discouraging palm oil industries.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sentence_rankings[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentenceSimilarity(label=-1, score=0.9880421, claim_text='Last year’s warmth was manifested across the planet, from the warm tropical ocean waters off the coast of northeastern Australia, where the Great Barrier Reef experienced its worst coral bleaching event on record and large scale coral death, to the Arctic, where sea ice hit regular monthly record lows and overall temperatures were also the warmest on record, at least from January through September 2016.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9875697, claim_text='Once natural influences, in particular the impact of El Niño and La Niña, are removed from the recent termperature record, there is no evidence of a significant change in the human contribution to climate change.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.9857534, claim_text=\"Some global warming 'skeptics' argue that the Earth's climate sensitivity is so low that a doubling of atmospheric CO2 will result in a surface temperature change on the order of 1°C or less, and that therefore global warming is nothing to worry about.\", evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.9852759, claim_text='the models predicted seven times as much warming as has been observed', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9850717, claim_text='(Kerr 2007) points out that the sunlight-reflecting haze that cools much of the planet seems to have thinned over the past decade or so.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9837619, claim_text='The latest  measurements involve the use of satellite gravimetry, estimating  the mass of terrain beneath by detecting slight changes in gravity as a  satellite passes overhead.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.98363626, claim_text='The \"decline\" refers to a decline in northern tree-rings, not global temperature, and is openly discussed in papers and the IPCC reports.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9836, claim_text='Latest IPCC Reports (AR5) have shown global mean temperature forecasts from the 2005 IPCC report exceeded actual readings.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.9834547, claim_text='The team of climate scientists notes that in failing to predict the warming ‘hiatus’ in the beginning of the 21st century, the Intergovernmental Panel on Climate Change (IPCC) models overestimated temperature increases…', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.98268914, claim_text='\"Three recent articles give us reason to question the alarmists’ claims  that coral reefs are in deep trouble due to the buildup of greenhouse  gases.\" (World Climate Report)', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.98245287, claim_text='In recent decades this warming has been accompanied by a constant rise in the sea level and, it would appear, by an increase of extreme weather events, even if a scientifically determinable cause cannot be assigned to each particular phenomenon.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.9821408, claim_text='CFCs contribute to global waerming at a small level.', evidence_text='Scientists Reach 100% Consensus on Anthropogenic Global Warming.'),\n",
       " SentenceSimilarity(label=-1, score=0.98203546, claim_text='The latest  measurements involve the use of satellite gravimetry, estimating  the mass of terrain beneath by detecting slight changes in gravity as a  satellite passes overhead.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.98185956, claim_text='In recent decades this warming has been accompanied by a constant rise in the sea level and, it would appear, by an increase of extreme weather events, even if a scientifically determinable cause cannot be assigned to each particular phenomenon.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9818259, claim_text='[T]he study indicates “Greenland’s ice may be less susceptible to the massive meltdown predicted by computer models of climate change, the main author ... said in an interview. ...', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.9811968, claim_text='The particular signature of warming in 2016 was also revealing in another way, Overpeck said, noting that the stratosphere… saw record cold temperatures last year', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.981022, claim_text='The motions of the massive oceans where heat is moved between deep layers and the surface provides variability on time scales from years to centuries.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9808647, claim_text=\"Multiple lines of evidence indicate Greenland's ice loss is accelerating and will contribute sea level rise in the order of metres over the next few centuries.\", evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.98054373, claim_text='the models predicted seven times as much warming as has been observed', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.98016775, claim_text='\"Austria is today seeing its earliest snowfall in history with 30 to 40 centimetres already predicted in the mountains.', evidence_text='The 2007 melt season let to a minimum 39% below the 1979–2000 average, and for the first time in human memory, the fabled Northwest Passage opened completely.'),\n",
       " SentenceSimilarity(label=-1, score=0.98011696, claim_text='The \"decline\" refers to a decline in northern tree-rings, not global temperature, and is openly discussed in papers and the IPCC reports.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.98006886, claim_text=\"Multiple lines of evidence indicate Greenland's ice loss is accelerating and will contribute sea level rise in the order of metres over the next few centuries.\", evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.98005897, claim_text='Latest IPCC Reports (AR5) have shown global mean temperature forecasts from the 2005 IPCC report exceeded actual readings.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.98002875, claim_text='Increases in atmospheric CO2 followed increases in temperature.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9800043, claim_text='The broader term covers changes beyond warmer temperatures, such as shifting rainfall patterns.”', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9798415, claim_text='Nor is there evidence of an increase in floods globally.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.9793499, claim_text='In many other cases, though — hurricanes, for example — the linkage to global warming for particular trends is uncertain or disputed.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.97920287, claim_text='The IPCC simply updated their temperature history graphs to show the best data available at the time.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.9790015, claim_text='Venus very likely underwent a runaway or ‘moist’ greenhouse phase earlier in its history, and today is kept hot by a dense CO2 atmosphere.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.97891986, claim_text='Global Warming history completely coincides with the history of artificial satellites and the use of microwave frequencies from outer space.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9788406, claim_text='Scientists studying Antarctica sea ice warn a rise in accumulation could spark the next ice age.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9786573, claim_text='IPCC overestimate temperature rise.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9785141, claim_text='But like most claims regarding global warming, the real effect is small, probably temporary, and most likely due to natural weather patterns', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.9783573, claim_text='Scientists retracted claim that sea levels are rising.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9782922, claim_text='Water vapor helps trap heat, and is a far the strongest of the major greenhouse gases, contributing 36–72 percent of the greenhouse effect.', evidence_text='Absorption of infrared light at the vibrational frequencies of atmospheric carbon dioxide traps energy near the surface, warming the surface and the lower atmosphere.'),\n",
       " SentenceSimilarity(label=-1, score=0.97823703, claim_text='The majority of peer reviewed research at the time predicted warming due to increasing CO2.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.9778183, claim_text=\"Hansen's 1988 results are evidence that the actual climate sensitivity is about 3°C for a doubling of atmospheric CO2.\", evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9777019, claim_text='Once natural influences, in particular the impact of El Niño and La Niña, are removed from the recent termperature record, there is no evidence of a significant change in the human contribution to climate change.', evidence_text='Scientists Reach 100% Consensus on Anthropogenic Global Warming.'),\n",
       " SentenceSimilarity(label=-1, score=0.977646, claim_text='The motions of the massive oceans where heat is moved between deep layers and the surface provides variability on time scales from years to centuries.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.9775609, claim_text=\"There are a myriad of other radiative forcings that affect the planet's energy imbalance.\", evidence_text='Absorption of infrared light at the vibrational frequencies of atmospheric carbon dioxide traps energy near the surface, warming the surface and the lower atmosphere.'),\n",
       " SentenceSimilarity(label=-1, score=0.97738993, claim_text='Around 97% of climate experts agree that humans are causing global warming.', evidence_text='\"How the oceans absorb carbon dioxide is critical for predicting climate change\".'),\n",
       " SentenceSimilarity(label=-1, score=0.9772793, claim_text='In many other cases, though — hurricanes, for example — the linkage to global warming for particular trends is uncertain or disputed.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9766494, claim_text=\"Some global warming 'skeptics' argue that the Earth's climate sensitivity is so low that a doubling of atmospheric CO2 will result in a surface temperature change on the order of 1°C or less, and that therefore global warming is nothing to worry about.\", evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.976648, claim_text='In fact, the authors go on to estimate climate sensitivity from their findings, calculate a value between 2.3 to 4.1°C.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.97657406, claim_text='[…] Constant 24-7  media coverage of every significant storm worldwide just makes it seem  that way.”', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.9764234, claim_text='The IPCC simply updated their temperature history graphs to show the best data available at the time.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.97625345, claim_text='Heat is continuing to build up in the subsurface ocean.', evidence_text='The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20\\xa0km (12\\xa0mi), a change associated with global warming in a relationship that is still under investigation.'),\n",
       " SentenceSimilarity(label=-1, score=0.9761872, claim_text='The team of climate scientists notes that in failing to predict the warming ‘hiatus’ in the beginning of the 21st century, the Intergovernmental Panel on Climate Change (IPCC) models overestimated temperature increases…', evidence_text='Scientists Reach 100% Consensus on Anthropogenic Global Warming.'),\n",
       " SentenceSimilarity(label=-1, score=0.9760002, claim_text='The most recent IPCC report lays out a future if we limit global heating to 1.5°C instead of the Paris Agreement’s 2°C.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.'),\n",
       " SentenceSimilarity(label=-1, score=0.97594106, claim_text='More than 100 climate models over the past 30 years did not predict what actually happened because it was assumed carbon dioxide had the pivotal role in driving climate change and that the effects of clouds, back-radiation and the sun were trivial.', evidence_text='Projections based on the Special Report on Emissions Scenarios suggest warming over the 21st century at a more rapid rate than that experienced for at least the last 10,000 years.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sentence_rankings[:50]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp90042_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
