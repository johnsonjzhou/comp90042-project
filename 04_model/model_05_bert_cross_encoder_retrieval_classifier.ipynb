{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 05 Bert Cross Entropy Classification for Retrieval\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to project root\n",
    "from pathlib import Path\n",
    "import os\n",
    "ROOT_DIR = Path.cwd()\n",
    "while not ROOT_DIR.joinpath(\"src\").exists():\n",
    "    ROOT_DIR = ROOT_DIR.parent\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/comp90042_project/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device is 'mps'\n"
     ]
    }
   ],
   "source": [
    "# Imports and dependencies\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from torcheval.metrics import BinaryAccuracy, BinaryF1Score\n",
    "\n",
    "from src.torch_utils import get_torch_device\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Union, Tuple\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from src.model_05 import BertCrossEncoderClassifier\n",
    "from src.data import RetrievalWithShortlistDataset, RetrievalDevEvalDataset\n",
    "from src.logger import SimpleLogger\n",
    "\n",
    "TORCH_DEVICE = get_torch_device()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = ROOT_DIR.joinpath(\"./result/models/*\")\n",
    "DATA_PATH = ROOT_DIR.joinpath(\"./data/*\")\n",
    "LOG_PATH = ROOT_DIR.joinpath(\"./result/logs/*\")\n",
    "SHORTLIST_PATH = ROOT_DIR.joinpath(\"./result/pipeline/shortlisting_v2/*\")\n",
    "\n",
    "run_time = datetime.now().strftime('%Y_%m_%d_%H_%M')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(\n",
    "    model,\n",
    "    claims_paths:List[Path],\n",
    "    claims_shortlist_paths:List[Path],\n",
    "    save_path:Path=None,\n",
    "    n_neg_samples:int=5,\n",
    "    warmup:float=0.1,\n",
    "    lr:float=0.00005, # 5e-5\n",
    "    weight_decay:float=0.01,\n",
    "    normalize_text:bool=True,\n",
    "    max_length:int=128,\n",
    "    dropout:float=None,\n",
    "    n_epochs:int=5,\n",
    "    batch_size:int=64,\n",
    "):\n",
    "    # Generate training dataset\n",
    "    train_data = RetrievalWithShortlistDataset(\n",
    "        claims_paths=claims_paths,\n",
    "        claims_shortlist_paths=claims_shortlist_paths,\n",
    "        n_neg_samples=n_neg_samples,\n",
    "        pos_label=1,\n",
    "        neg_label=0\n",
    "    )\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    # Generate evaluation dataset\n",
    "    dev_data = RetrievalDevEvalDataset(\n",
    "        n_neg_samples=n_neg_samples,\n",
    "        pos_label=1,\n",
    "        neg_label=0,\n",
    "    )\n",
    "    dev_dataloader = DataLoader(\n",
    "        dataset=dev_data,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    # Loss function\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = AdamW(\n",
    "        params=model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler = LinearLR(\n",
    "        optimizer=optimizer,\n",
    "        total_iters=warmup * len(train_dataloader),\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy_fn = BinaryAccuracy()\n",
    "    f1_fn = BinaryF1Score()\n",
    "    \n",
    "    # Training epochs --------------------------------------------------------\n",
    "    \n",
    "    best_epoch_loss = 999\n",
    "    best_epoch_f1 = -1\n",
    "    best_epoch_acc = -1\n",
    "    best_epoch = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        print(f\"Epoch: {epoch + 1} of {n_epochs}\\n\")\n",
    "        \n",
    "        # Run training -------------------------------------------------------\n",
    "        model.train()\n",
    "        \n",
    "        train_batches = tqdm(train_dataloader, desc=\"train batches\")\n",
    "        running_losses = []\n",
    "        for batch in train_batches:\n",
    "            claim_texts, evidence_texts, labels, claim_ids, evidence_ids = batch\n",
    "            texts = list(zip(claim_texts, evidence_texts))\n",
    "            \n",
    "            # Reset optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward + loss\n",
    "            output, logits, seq = model(\n",
    "                texts=texts,\n",
    "                normalize_text=normalize_text,\n",
    "                max_length=max_length,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "            # Backward + optimizer\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update running loss\n",
    "            batch_loss = loss.item() * len(batch)\n",
    "            running_losses.append(batch_loss)\n",
    "            \n",
    "            train_batches.postfix = f\"loss: {batch_loss:.3f}\"\n",
    "            \n",
    "            # Update scheduler\n",
    "            scheduler.step()\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        # Epoch loss\n",
    "        epoch_loss = np.average(running_losses)\n",
    "        print(f\"Average epoch loss: {epoch_loss:.3f}\")\n",
    "    \n",
    "        # Run evaluation ------------------------------------------------------\n",
    "        model.eval()\n",
    "\n",
    "        dev_batches = tqdm(dev_dataloader, desc=\"dev batches\")\n",
    "        dev_acc = []\n",
    "        dev_f1 = []\n",
    "        for batch in dev_batches:\n",
    "            claim_texts, evidence_texts, labels, claim_ids, evidence_ids = batch\n",
    "            texts = list(zip(claim_texts, evidence_texts))\n",
    "\n",
    "            # Forward\n",
    "            output, logits, seq = model(\n",
    "                texts=texts,\n",
    "                normalize_text=normalize_text,\n",
    "                max_length=max_length,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            \n",
    "            # Prediction\n",
    "            _, predicted = torch.max(output, dim=-1)\n",
    "\n",
    "            # Metrics\n",
    "            accuracy_fn.update(predicted.cpu(), labels.cpu())\n",
    "            f1_fn.update(predicted.cpu(), labels.cpu())\n",
    "            \n",
    "            acc = accuracy_fn.compute()\n",
    "            f1 = f1_fn.compute()\n",
    "            \n",
    "            dev_acc.append(acc)\n",
    "            dev_f1.append(f1)\n",
    "            \n",
    "            dev_batches.postfix = f\" acc: {acc:.3f}, f1: {f1:.3f}\"\n",
    "\n",
    "            continue\n",
    "        \n",
    "        # Consider metrics\n",
    "        epoch_acc = np.average(dev_acc)\n",
    "        print(f\"Average epoch accuracy: {epoch_acc:.3f}\")\n",
    "        \n",
    "        epoch_f1 = np.average(dev_f1)\n",
    "        print(f\"Average epoch f1: {epoch_f1:.3f}\")\n",
    "        \n",
    "        if epoch_acc > best_epoch_acc:\n",
    "            best_epoch_acc = epoch_acc\n",
    "        \n",
    "        if epoch_f1 > best_epoch_f1:\n",
    "            best_epoch_f1 = epoch_f1\n",
    "            best_epoch = epoch + 1\n",
    "        \n",
    "        # Save model ----------------------------------------------------------\n",
    "        \n",
    "        # Save the model with the best f1 score\n",
    "        if save_path and epoch_f1 >= best_epoch_f1:\n",
    "            torch.save(model, save_path)\n",
    "            print(f\"Saved model to: {save_path}\")\n",
    "        \n",
    "    print(\"Done!\")\n",
    "    return best_epoch_acc, best_epoch_f1, best_epoch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a blank pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertCrossEncoderClassifier(\n",
    "    pretrained_name=\"bert-base-uncased\",\n",
    "    n_classes=2,\n",
    "    device=TORCH_DEVICE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or load one previously trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_SAVE_PATH = MODEL_PATH.with_name(\"\")\n",
    "# with open(MODEL_PATH.with_name(MODEL_SAVE_PATH), mode=\"rb\") as f:\n",
    "#     model = torch.load(f, map_location=TORCH_DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 109088.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=7806\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 347644.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=953\n",
      "Epoch: 1 of 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [07:08<00:00,  1.31s/it, loss: 1.305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 2.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.56it/s,  acc: 0.771, f1: 0.804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.784\n",
      "Average epoch f1: 0.817\n",
      "Saved model to: /Users/johnsonzhou/git/comp90042-project/result/models/model_05_bert_cross_encoder_retrieval_2023_05_08_17_06.pth\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7835601, 0.81668675, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    model=model,\n",
    "    claims_paths=[\n",
    "        DATA_PATH.with_name(\"train-claims.json\")\n",
    "    ],\n",
    "    claims_shortlist_paths=[\n",
    "        Path(\"./result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json\"),\n",
    "    ],\n",
    "    save_path=MODEL_PATH.with_name(f\"model_05_bert_cross_encoder_retrieval_{run_time}.pth\"),\n",
    "    n_neg_samples=3,\n",
    "    warmup=0.1,\n",
    "    lr=0.000005, # 5e-6\n",
    "    weight_decay=0.02,\n",
    "    normalize_text=True,\n",
    "    max_length=512,\n",
    "    dropout=0.1,\n",
    "    n_epochs=1,\n",
    "    batch_size=24,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = ParameterGrid(param_grid={\n",
    "    \"claims_paths\": [[\n",
    "        DATA_PATH.with_name(\"train-claims.json\")\n",
    "    ]],\n",
    "    \"claims_shortlist_paths\": [[\n",
    "        Path(\"./result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json\"),\n",
    "    ]],\n",
    "    \"n_neg_samples\": [3, 5, 10],\n",
    "    \"warmup\": [0.1],\n",
    "    \"lr\": [0.00005, 0.0005],\n",
    "    \"weight_decay\": [0.01, 0.02],\n",
    "    \"normalize_text\": [True, False],\n",
    "    \"max_length\": [512],\n",
    "    \"dropout\": [None, 0.1],\n",
    "    \"n_epochs\": [5, 10],\n",
    "    \"batch_size\": [24]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 13:47:41 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-07 13:47:41 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 127332.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=7806\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 406240.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=953\n",
      "Epoch: 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [07:13<00:00,  1.33s/it, loss: 1.024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.53it/s,  acc: 0.799, f1: 0.820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.811\n",
      "Average epoch f1: 0.834\n",
      "Epoch: 2 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [07:08<00:00,  1.31s/it, loss: 0.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.58it/s,  acc: 0.687, f1: 0.754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.728\n",
      "Average epoch f1: 0.778\n",
      "Epoch: 3 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [07:04<00:00,  1.30s/it, loss: 0.012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.57it/s,  acc: 0.661, f1: 0.738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.672\n",
      "Average epoch f1: 0.746\n",
      "Epoch: 4 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [07:04<00:00,  1.30s/it, loss: 0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.58it/s,  acc: 0.667, f1: 0.739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.664\n",
      "Average epoch f1: 0.739\n",
      "Epoch: 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [07:04<00:00,  1.30s/it, loss: 0.010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.57it/s,  acc: 0.653, f1: 0.729]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.659\n",
      "Average epoch f1: 0.733\n",
      "Done!\n",
      "2023-05-07 14:24:36 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 1, run_best_acc: 0.811083972454071, run_best_f1: 0.8339534997940063\n",
      "\n",
      "2023-05-07 14:24:36 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-07 14:24:36 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 14:24:45 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-07 14:24:45 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.02}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 166578.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=7806\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 328379.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=953\n",
      "Epoch: 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [07:06<00:00,  1.31s/it, loss: 1.680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.57it/s,  acc: 0.665, f1: 0.727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.673\n",
      "Average epoch f1: 0.736\n",
      "Epoch: 2 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [07:09<00:00,  1.32s/it, loss: 1.170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.55it/s,  acc: 0.741, f1: 0.783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.712\n",
      "Average epoch f1: 0.763\n",
      "Epoch: 3 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [07:10<00:00,  1.32s/it, loss: 0.063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.54it/s,  acc: 0.739, f1: 0.781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.739\n",
      "Average epoch f1: 0.782\n",
      "Epoch: 4 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [07:10<00:00,  1.32s/it, loss: 0.013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.55it/s,  acc: 0.735, f1: 0.781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.737\n",
      "Average epoch f1: 0.781\n",
      "Epoch: 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [07:10<00:00,  1.32s/it, loss: 0.018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.55it/s,  acc: 0.735, f1: 0.781]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.736\n",
      "Average epoch f1: 0.782\n",
      "Done!\n",
      "2023-05-07 15:01:52 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 5, run_best_acc: 0.738613486289978, run_best_f1: 0.7822245359420776\n",
      "\n",
      "2023-05-07 15:01:52 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-07 15:01:52 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 15:01:54 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-07 15:01:54 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': False, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 344268.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=7806\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 267795.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=953\n",
      "Epoch: 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  61%|██████    | 198/326 [04:25<02:50,  1.34s/it, loss: 1.082]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [07:15<00:00,  1.33s/it, loss: 0.727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.57it/s,  acc: 0.706, f1: 0.770]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.709\n",
      "Average epoch f1: 0.776\n",
      "Epoch: 2 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  57%|█████▋    | 186/326 [04:07<03:06,  1.33s/it, loss: 0.732]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [07:12<00:00,  1.33s/it, loss: 0.057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.57it/s,  acc: 0.722, f1: 0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.718\n",
      "Average epoch f1: 0.777\n",
      "Epoch: 3 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  27%|██▋       | 87/326 [01:56<05:18,  1.33s/it, loss: 0.298]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [07:13<00:00,  1.33s/it, loss: 0.482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.58it/s,  acc: 0.680, f1: 0.749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.698\n",
      "Average epoch f1: 0.761\n",
      "Epoch: 4 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  56%|█████▌    | 181/326 [04:00<03:14,  1.34s/it, loss: 0.057]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [07:13<00:00,  1.33s/it, loss: 0.006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.56it/s,  acc: 0.659, f1: 0.738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.670\n",
      "Average epoch f1: 0.744\n",
      "Epoch: 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   5%|▌         | 17/326 [00:22<06:52,  1.34s/it, loss: 0.043]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [07:11<00:00,  1.32s/it, loss: 0.006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.57it/s,  acc: 0.654, f1: 0.735]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.657\n",
      "Average epoch f1: 0.737\n",
      "Done!\n",
      "2023-05-07 15:39:19 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 2, run_best_acc: 0.718364953994751, run_best_f1: 0.7765060663223267\n",
      "\n",
      "2023-05-07 15:39:19 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-07 15:39:19 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 15:39:21 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-07 15:39:21 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': False, 'warmup': 0.1, 'weight_decay': 0.02}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 161719.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=7806\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 334848.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=953\n",
      "Epoch: 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   7%|▋         | 23/326 [00:31<06:39,  1.32s/it, loss: 2.083]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [07:11<00:00,  1.32s/it, loss: 0.343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.56it/s,  acc: 0.785, f1: 0.817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.785\n",
      "Average epoch f1: 0.820\n",
      "Epoch: 2 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  58%|█████▊    | 190/326 [04:11<03:01,  1.33s/it, loss: 0.050]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [07:10<00:00,  1.32s/it, loss: 0.152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.51it/s,  acc: 0.732, f1: 0.782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.749\n",
      "Average epoch f1: 0.793\n",
      "Epoch: 3 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  55%|█████▍    | 178/326 [03:55<03:15,  1.32s/it, loss: 0.986]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [07:09<00:00,  1.32s/it, loss: 0.535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.57it/s,  acc: 0.678, f1: 0.749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.703\n",
      "Average epoch f1: 0.764\n",
      "Epoch: 4 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  99%|█████████▉| 324/326 [07:07<00:02,  1.32s/it, loss: 0.080]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [07:09<00:00,  1.32s/it, loss: 0.009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.56it/s,  acc: 0.644, f1: 0.730]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.660\n",
      "Average epoch f1: 0.739\n",
      "Epoch: 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  53%|█████▎    | 173/326 [03:48<03:22,  1.33s/it, loss: 0.118]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [07:10<00:00,  1.32s/it, loss: 0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.54it/s,  acc: 0.640, f1: 0.727]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.642\n",
      "Average epoch f1: 0.729\n",
      "Done!\n",
      "2023-05-07 16:16:31 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 1, run_best_acc: 0.7852210998535156, run_best_f1: 0.8198814392089844\n",
      "\n",
      "2023-05-07 16:16:31 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-07 16:16:31 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 16:16:33 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-07 16:16:33 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 5, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 134991.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=10260\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 245972.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=1261\n",
      "Epoch: 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:33<00:00,  1.34s/it, loss: 0.990]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.54it/s,  acc: 0.715, f1: 0.707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.730\n",
      "Average epoch f1: 0.725\n",
      "Epoch: 2 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:41<00:00,  1.36s/it, loss: 0.052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:21<00:00,  2.45it/s,  acc: 0.742, f1: 0.718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.735\n",
      "Average epoch f1: 0.718\n",
      "Epoch: 3 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:42<00:00,  1.36s/it, loss: 0.026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:21<00:00,  2.48it/s,  acc: 0.703, f1: 0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.720\n",
      "Average epoch f1: 0.706\n",
      "Epoch: 4 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:42<00:00,  1.36s/it, loss: 0.018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:21<00:00,  2.47it/s,  acc: 0.677, f1: 0.679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.689\n",
      "Average epoch f1: 0.687\n",
      "Epoch: 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:43<00:00,  1.36s/it, loss: 0.004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:21<00:00,  2.46it/s,  acc: 0.656, f1: 0.668]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.666\n",
      "Average epoch f1: 0.673\n",
      "Done!\n",
      "2023-05-07 17:06:45 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 1, run_best_acc: 0.7351115942001343, run_best_f1: 0.724618136882782\n",
      "\n",
      "2023-05-07 17:06:45 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-07 17:06:45 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 17:06:52 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-07 17:06:52 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 5, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.02}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 148685.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=10260\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 198684.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=1261\n",
      "Epoch: 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:32<00:00,  1.34s/it, loss: 0.759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.52it/s,  acc: 0.695, f1: 0.684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.696\n",
      "Average epoch f1: 0.689\n",
      "Epoch: 2 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:33<00:00,  1.34s/it, loss: 0.075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.53it/s,  acc: 0.743, f1: 0.721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.721\n",
      "Average epoch f1: 0.706\n",
      "Epoch: 3 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:34<00:00,  1.34s/it, loss: 0.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.54it/s,  acc: 0.706, f1: 0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.723\n",
      "Average epoch f1: 0.710\n",
      "Epoch: 4 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:35<00:00,  1.34s/it, loss: 0.010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:21<00:00,  2.51it/s,  acc: 0.670, f1: 0.679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.686\n",
      "Average epoch f1: 0.688\n",
      "Epoch: 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:36<00:00,  1.35s/it, loss: 0.014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:21<00:00,  2.50it/s,  acc: 0.661, f1: 0.673]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.665\n",
      "Average epoch f1: 0.676\n",
      "Done!\n",
      "2023-05-07 17:56:32 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 3, run_best_acc: 0.7225133776664734, run_best_f1: 0.71006840467453\n",
      "\n",
      "2023-05-07 17:56:32 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-07 17:56:32 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 17:56:33 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-07 17:56:33 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 5, 'normalize_text': False, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 147615.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=10260\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 264073.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=1261\n",
      "Epoch: 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  44%|████▍     | 188/428 [04:08<05:14,  1.31s/it, loss: 1.511]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  46%|████▌     | 195/428 [04:17<05:10,  1.33s/it, loss: 1.335]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  61%|██████    | 261/428 [05:44<03:40,  1.32s/it, loss: 1.099]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  85%|████████▍ | 362/428 [07:56<01:25,  1.30s/it, loss: 1.061]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  86%|████████▋ | 370/428 [08:06<01:15,  1.30s/it, loss: 1.090]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  92%|█████████▏| 393/428 [08:36<00:45,  1.31s/it, loss: 0.821]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  94%|█████████▎| 401/428 [08:47<00:35,  1.30s/it, loss: 0.734]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 428/428 [09:21<00:00,  1.31s/it, loss: 0.643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.62it/s,  acc: 0.642, f1: 0.669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.658\n",
      "Average epoch f1: 0.687\n",
      "Epoch: 2 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  18%|█▊        | 77/428 [01:39<07:34,  1.29s/it, loss: 0.894]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  25%|██▍       | 105/428 [02:15<06:57,  1.29s/it, loss: 0.203]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  27%|██▋       | 114/428 [02:27<06:47,  1.30s/it, loss: 0.920]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  32%|███▏      | 137/428 [02:57<06:15,  1.29s/it, loss: 0.519]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  59%|█████▉    | 253/428 [05:27<03:46,  1.29s/it, loss: 0.641]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  73%|███████▎  | 313/428 [06:45<02:28,  1.30s/it, loss: 0.141]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  92%|█████████▏| 395/428 [08:31<00:42,  1.28s/it, loss: 0.263]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 428/428 [09:12<00:00,  1.29s/it, loss: 0.177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:19<00:00,  2.65it/s,  acc: 0.670, f1: 0.677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.659\n",
      "Average epoch f1: 0.675\n",
      "Epoch: 3 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  14%|█▍        | 60/428 [01:16<07:50,  1.28s/it, loss: 1.208]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  50%|█████     | 215/428 [04:34<04:32,  1.28s/it, loss: 0.902]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  60%|██████    | 258/428 [05:29<03:40,  1.30s/it, loss: 0.245]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  76%|███████▌  | 326/428 [06:58<02:14,  1.31s/it, loss: 0.383]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  85%|████████▌ | 365/428 [07:49<01:23,  1.32s/it, loss: 0.239]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  89%|████████▉ | 380/428 [08:09<01:03,  1.32s/it, loss: 0.237]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 428/428 [09:11<00:00,  1.29s/it, loss: 0.147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.61it/s,  acc: 0.654, f1: 0.671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.660\n",
      "Average epoch f1: 0.673\n",
      "Epoch: 4 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   5%|▍         | 21/428 [00:27<08:49,  1.30s/it, loss: 0.202]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  20%|██        | 87/428 [01:53<07:25,  1.31s/it, loss: 0.226]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  28%|██▊       | 119/428 [02:35<06:42,  1.30s/it, loss: 0.015]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  54%|█████▎    | 229/428 [04:58<04:17,  1.29s/it, loss: 0.172]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  64%|██████▍   | 276/428 [05:59<03:16,  1.30s/it, loss: 0.101]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  68%|██████▊   | 292/428 [06:20<02:56,  1.30s/it, loss: 0.488]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  75%|███████▍  | 320/428 [06:56<02:20,  1.30s/it, loss: 0.016]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 428/428 [09:16<00:00,  1.30s/it, loss: 0.351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.62it/s,  acc: 0.638, f1: 0.659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.646\n",
      "Average epoch f1: 0.665\n",
      "Epoch: 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   2%|▏         | 7/428 [00:09<09:09,  1.31s/it, loss: 0.068]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:   7%|▋         | 29/428 [00:37<08:37,  1.30s/it, loss: 1.912]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  17%|█▋        | 72/428 [01:33<07:43,  1.30s/it, loss: 0.025]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  41%|████      | 174/428 [03:47<05:29,  1.30s/it, loss: 0.042]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  72%|███████▏  | 309/428 [06:42<02:34,  1.30s/it, loss: 0.017]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  88%|████████▊ | 375/428 [08:08<01:09,  1.30s/it, loss: 0.044]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  89%|████████▊ | 379/428 [08:13<01:04,  1.32s/it, loss: 0.002]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 428/428 [09:17<00:00,  1.30s/it, loss: 0.004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.61it/s,  acc: 0.611, f1: 0.644]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.623\n",
      "Average epoch f1: 0.651\n",
      "Done!\n",
      "2023-05-07 18:44:37 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 1, run_best_acc: 0.6596076488494873, run_best_f1: 0.687384843826294\n",
      "\n",
      "2023-05-07 18:44:37 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-07 18:44:37 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 18:44:39 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-07 18:44:39 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 5, 'normalize_text': False, 'warmup': 0.1, 'weight_decay': 0.02}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 10706.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=10260\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 259302.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=1261\n",
      "Epoch: 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   8%|▊         | 34/428 [00:45<08:32,  1.30s/it, loss: 2.579]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  11%|█         | 45/428 [00:59<08:20,  1.31s/it, loss: 1.606]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  28%|██▊       | 118/428 [02:35<06:45,  1.31s/it, loss: 0.973]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  36%|███▌      | 152/428 [03:19<06:03,  1.32s/it, loss: 1.614]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  68%|██████▊   | 293/428 [06:23<02:56,  1.31s/it, loss: 1.002]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  75%|███████▌  | 323/428 [07:03<02:16,  1.30s/it, loss: 0.215]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  79%|███████▉  | 340/428 [07:25<01:54,  1.30s/it, loss: 0.685]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 428/428 [09:19<00:00,  1.31s/it, loss: 2.546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.61it/s,  acc: 0.746, f1: 0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.738\n",
      "Average epoch f1: 0.731\n",
      "Epoch: 2 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   5%|▌         | 22/428 [00:28<08:50,  1.31s/it, loss: 0.092]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:   6%|▌         | 26/428 [00:34<08:43,  1.30s/it, loss: 0.395]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  39%|███▉      | 166/428 [03:37<05:44,  1.32s/it, loss: 0.074]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  54%|█████▍    | 231/428 [05:02<04:16,  1.30s/it, loss: 1.091]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  60%|██████    | 258/428 [05:37<03:40,  1.29s/it, loss: 0.718]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  86%|████████▌ | 367/428 [07:59<01:19,  1.31s/it, loss: 0.294]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  89%|████████▉ | 381/428 [08:18<01:01,  1.31s/it, loss: 0.039]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 428/428 [09:18<00:00,  1.30s/it, loss: 0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.65it/s,  acc: 0.693, f1: 0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.715\n",
      "Average epoch f1: 0.710\n",
      "Epoch: 3 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   1%|          | 4/428 [00:05<09:06,  1.29s/it, loss: 0.067]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  12%|█▏        | 51/428 [01:05<08:01,  1.28s/it, loss: 0.028]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  15%|█▌        | 66/428 [01:24<07:42,  1.28s/it, loss: 0.982]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  18%|█▊        | 77/428 [01:39<07:33,  1.29s/it, loss: 0.398]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  81%|████████  | 346/428 [07:26<01:44,  1.28s/it, loss: 0.498]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  96%|█████████▌| 409/428 [08:47<00:24,  1.29s/it, loss: 0.011]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  99%|█████████▉| 424/428 [09:06<00:05,  1.29s/it, loss: 0.286]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 428/428 [09:11<00:00,  1.29s/it, loss: 0.216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:19<00:00,  2.65it/s,  acc: 0.655, f1: 0.670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.672\n",
      "Average epoch f1: 0.681\n",
      "Epoch: 4 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  10%|█         | 43/428 [00:55<08:11,  1.28s/it, loss: 0.109]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  25%|██▍       | 106/428 [02:16<06:51,  1.28s/it, loss: 1.065]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  47%|████▋     | 203/428 [04:21<04:49,  1.28s/it, loss: 0.078]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  68%|██████▊   | 293/428 [06:16<02:52,  1.28s/it, loss: 0.090]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  74%|███████▍  | 317/428 [06:47<02:23,  1.29s/it, loss: 0.011]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  90%|████████▉ | 384/428 [08:13<00:56,  1.29s/it, loss: 0.095]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 428/428 [09:09<00:00,  1.28s/it, loss: 0.020]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:19<00:00,  2.65it/s,  acc: 0.648, f1: 0.667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.651\n",
      "Average epoch f1: 0.669\n",
      "Epoch: 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  39%|███▉      | 169/428 [03:37<05:34,  1.29s/it, loss: 0.009]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  48%|████▊     | 206/428 [04:25<04:44,  1.28s/it, loss: 0.071]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  52%|█████▏    | 221/428 [04:44<04:27,  1.29s/it, loss: 0.128]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  57%|█████▋    | 242/428 [05:11<03:59,  1.29s/it, loss: 0.036]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  57%|█████▋    | 245/428 [05:15<03:57,  1.30s/it, loss: 0.020]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  84%|████████▍ | 359/428 [07:42<01:28,  1.29s/it, loss: 0.052]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  95%|█████████▌| 407/428 [08:44<00:27,  1.29s/it, loss: 0.087]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 428/428 [09:10<00:00,  1.29s/it, loss: 0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.65it/s,  acc: 0.628, f1: 0.656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.637\n",
      "Average epoch f1: 0.661\n",
      "Done!\n",
      "2023-05-07 19:32:30 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 1, run_best_acc: 0.7382638454437256, run_best_f1: 0.7312518954277039\n",
      "\n",
      "2023-05-07 19:32:30 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-07 19:32:30 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 19:32:36 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-07 19:32:36 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 10, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 120237.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=16395\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 180123.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=2031\n",
      "Epoch: 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 684/684 [14:42<00:00,  1.29s/it, loss: 0.731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.61it/s,  acc: 0.650, f1: 0.550]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.655\n",
      "Average epoch f1: 0.567\n",
      "Epoch: 2 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 684/684 [14:39<00:00,  1.29s/it, loss: 0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.61it/s,  acc: 0.698, f1: 0.580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.679\n",
      "Average epoch f1: 0.570\n",
      "Epoch: 3 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 684/684 [14:38<00:00,  1.28s/it, loss: 0.032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.62it/s,  acc: 0.670, f1: 0.561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.681\n",
      "Average epoch f1: 0.570\n",
      "Epoch: 4 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 684/684 [14:37<00:00,  1.28s/it, loss: 0.005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.61it/s,  acc: 0.647, f1: 0.540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.657\n",
      "Average epoch f1: 0.551\n",
      "Epoch: 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 684/684 [14:39<00:00,  1.29s/it, loss: 0.146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.62it/s,  acc: 0.658, f1: 0.547]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.652\n",
      "Average epoch f1: 0.544\n",
      "Done!\n",
      "2023-05-07 20:48:37 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 2, run_best_acc: 0.6814714074134827, run_best_f1: 0.5700081586837769\n",
      "\n",
      "2023-05-07 20:48:37 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-07 20:48:37 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 20:48:39 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-07 20:48:39 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 10, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.02}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 121596.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=16395\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 172614.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=2031\n",
      "Epoch: 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 684/684 [14:48<00:00,  1.30s/it, loss: 0.185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:33<00:00,  2.57it/s,  acc: 0.721, f1: 0.599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.730\n",
      "Average epoch f1: 0.619\n",
      "Epoch: 2 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 684/684 [14:55<00:00,  1.31s/it, loss: 0.161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.62it/s,  acc: 0.713, f1: 0.592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.717\n",
      "Average epoch f1: 0.598\n",
      "Epoch: 3 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 684/684 [14:37<00:00,  1.28s/it, loss: 0.036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.62it/s,  acc: 0.692, f1: 0.581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.700\n",
      "Average epoch f1: 0.587\n",
      "Epoch: 4 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 684/684 [14:37<00:00,  1.28s/it, loss: 0.014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.62it/s,  acc: 0.696, f1: 0.579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.695\n",
      "Average epoch f1: 0.581\n",
      "Epoch: 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 684/684 [14:36<00:00,  1.28s/it, loss: 0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.62it/s,  acc: 0.684, f1: 0.569]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.690\n",
      "Average epoch f1: 0.575\n",
      "Done!\n",
      "2023-05-07 22:04:59 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 1, run_best_acc: 0.7300872206687927, run_best_f1: 0.619188666343689\n",
      "\n",
      "2023-05-07 22:04:59 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-07 22:04:59 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 22:05:01 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-07 22:05:01 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 10, 'normalize_text': False, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 120226.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=16395\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 173030.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=2031\n",
      "Epoch: 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   5%|▍         | 33/684 [00:43<14:00,  1.29s/it, loss: 3.001]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  11%|█         | 73/684 [01:35<13:07,  1.29s/it, loss: 2.748]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  13%|█▎        | 88/684 [01:54<12:46,  1.29s/it, loss: 1.871]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  17%|█▋        | 115/684 [02:29<12:11,  1.29s/it, loss: 1.933]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  26%|██▌       | 179/684 [03:52<10:52,  1.29s/it, loss: 1.001]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  35%|███▌      | 240/684 [05:10<09:31,  1.29s/it, loss: 0.574]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  60%|█████▉    | 408/684 [08:47<05:57,  1.29s/it, loss: 0.971]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  71%|███████   | 486/684 [10:28<04:16,  1.29s/it, loss: 1.539]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  75%|███████▌  | 514/684 [11:04<03:39,  1.29s/it, loss: 1.069]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  85%|████████▌ | 582/684 [12:32<02:12,  1.29s/it, loss: 0.596]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  86%|████████▋ | 590/684 [12:43<02:01,  1.30s/it, loss: 0.668]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  88%|████████▊ | 603/684 [12:59<01:44,  1.30s/it, loss: 1.892]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  96%|█████████▌| 654/684 [14:05<00:38,  1.29s/it, loss: 0.556]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  96%|█████████▋| 660/684 [14:13<00:31,  1.30s/it, loss: 1.713]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 684/684 [14:43<00:00,  1.29s/it, loss: 0.801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.63it/s,  acc: 0.670, f1: 0.564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.673\n",
      "Average epoch f1: 0.579\n",
      "Epoch: 2 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  13%|█▎        | 91/684 [01:57<12:42,  1.29s/it, loss: 0.655]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  21%|██        | 141/684 [03:01<11:40,  1.29s/it, loss: 1.694]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  21%|██▏       | 146/684 [03:08<11:34,  1.29s/it, loss: 0.172]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  33%|███▎      | 223/684 [04:47<09:55,  1.29s/it, loss: 0.115]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  40%|████      | 274/684 [05:53<08:48,  1.29s/it, loss: 0.083]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  44%|████▍     | 304/684 [06:32<08:09,  1.29s/it, loss: 0.570]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  58%|█████▊    | 399/684 [08:34<06:07,  1.29s/it, loss: 0.063]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  61%|██████    | 416/684 [08:56<05:45,  1.29s/it, loss: 0.265]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  67%|██████▋   | 460/684 [09:53<04:47,  1.29s/it, loss: 0.516]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  75%|███████▌  | 514/684 [11:02<03:38,  1.29s/it, loss: 0.902]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  84%|████████▍ | 573/684 [12:18<02:22,  1.28s/it, loss: 1.204]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  85%|████████▌ | 583/684 [12:31<02:10,  1.29s/it, loss: 0.668]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  88%|████████▊ | 605/684 [13:00<01:41,  1.29s/it, loss: 0.258]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  94%|█████████▎| 641/684 [13:46<00:55,  1.29s/it, loss: 0.077]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  96%|█████████▌| 656/684 [14:05<00:36,  1.29s/it, loss: 0.331]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 684/684 [14:40<00:00,  1.29s/it, loss: 0.091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.63it/s,  acc: 0.712, f1: 0.590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.694\n",
      "Average epoch f1: 0.580\n",
      "Epoch: 3 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   1%|          | 5/684 [00:06<14:36,  1.29s/it, loss: 0.040]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:   9%|▉         | 60/684 [01:17<13:25,  1.29s/it, loss: 0.888]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  23%|██▎       | 157/684 [03:22<11:19,  1.29s/it, loss: 0.031]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  31%|███       | 212/684 [04:33<10:08,  1.29s/it, loss: 0.134]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  32%|███▏      | 219/684 [04:42<10:00,  1.29s/it, loss: 0.026]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  37%|███▋      | 253/684 [05:26<09:16,  1.29s/it, loss: 0.039]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  55%|█████▌    | 378/684 [08:07<06:35,  1.29s/it, loss: 0.300]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  69%|██████▊   | 470/684 [10:06<04:35,  1.29s/it, loss: 0.081]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  70%|██████▉   | 476/684 [10:13<04:28,  1.29s/it, loss: 0.136]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  76%|███████▌  | 518/684 [11:08<03:34,  1.29s/it, loss: 0.047]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  82%|████████▏ | 560/684 [12:02<02:40,  1.29s/it, loss: 0.048]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  87%|████████▋ | 598/684 [12:51<01:50,  1.29s/it, loss: 1.377]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  93%|█████████▎| 638/684 [13:42<00:59,  1.29s/it, loss: 0.601]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  97%|█████████▋| 664/684 [14:16<00:25,  1.29s/it, loss: 0.004]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|█████████▉| 682/684 [14:39<00:02,  1.29s/it, loss: 0.758]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 684/684 [14:41<00:00,  1.29s/it, loss: 0.008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.63it/s,  acc: 0.676, f1: 0.560]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.692\n",
      "Average epoch f1: 0.574\n",
      "Epoch: 4 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  19%|█▉        | 131/684 [02:48<11:49,  1.28s/it, loss: 0.010]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  20%|██        | 140/684 [03:00<11:40,  1.29s/it, loss: 0.214]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  22%|██▏       | 153/684 [03:16<11:23,  1.29s/it, loss: 0.015]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  26%|██▌       | 175/684 [03:45<10:57,  1.29s/it, loss: 0.020]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  29%|██▊       | 195/684 [04:10<10:29,  1.29s/it, loss: 0.005]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  30%|███       | 207/684 [04:26<10:15,  1.29s/it, loss: 0.002]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  38%|███▊      | 261/684 [05:35<09:02,  1.28s/it, loss: 0.072]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  43%|████▎     | 297/684 [06:22<08:17,  1.29s/it, loss: 0.237]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  54%|█████▎    | 367/684 [07:52<06:46,  1.28s/it, loss: 0.062]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  66%|██████▌   | 451/684 [09:40<04:59,  1.28s/it, loss: 0.004]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  71%|███████   | 483/684 [10:21<04:17,  1.28s/it, loss: 0.038]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  76%|███████▌  | 520/684 [11:08<03:31,  1.29s/it, loss: 0.329]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  78%|███████▊  | 531/684 [11:22<03:17,  1.29s/it, loss: 0.004]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  93%|█████████▎| 634/684 [13:35<01:04,  1.29s/it, loss: 0.086]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 684/684 [14:38<00:00,  1.28s/it, loss: 0.014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.64it/s,  acc: 0.687, f1: 0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.682\n",
      "Average epoch f1: 0.562\n",
      "Epoch: 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   6%|▌         | 40/684 [00:51<13:49,  1.29s/it, loss: 0.003]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  14%|█▎        | 94/684 [02:01<12:40,  1.29s/it, loss: 0.011]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  20%|█▉        | 135/684 [02:54<11:47,  1.29s/it, loss: 0.049]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  24%|██▎       | 161/684 [03:27<11:12,  1.29s/it, loss: 0.043]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  24%|██▍       | 164/684 [03:31<11:09,  1.29s/it, loss: 0.023]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  38%|███▊      | 261/684 [05:36<09:04,  1.29s/it, loss: 0.002]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  61%|██████    | 418/684 [08:59<05:43,  1.29s/it, loss: 0.009]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  68%|██████▊   | 464/684 [09:58<04:42,  1.29s/it, loss: 0.098]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  68%|██████▊   | 467/684 [10:02<04:39,  1.29s/it, loss: 0.020]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  70%|███████   | 482/684 [10:21<04:20,  1.29s/it, loss: 0.009]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  71%|███████▏  | 489/684 [10:30<04:11,  1.29s/it, loss: 0.148]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  83%|████████▎ | 565/684 [12:08<02:33,  1.29s/it, loss: 0.035]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  88%|████████▊ | 600/684 [12:53<01:48,  1.29s/it, loss: 0.009]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  90%|████████▉ | 613/684 [13:10<01:31,  1.29s/it, loss: 0.476]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|█████████▉| 681/684 [14:38<00:03,  1.29s/it, loss: 0.054]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 684/684 [14:40<00:00,  1.29s/it, loss: 0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.63it/s,  acc: 0.652, f1: 0.537]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.667\n",
      "Average epoch f1: 0.548\n",
      "Done!\n",
      "2023-05-07 23:21:09 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 2, run_best_acc: 0.6937678456306458, run_best_f1: 0.5799320936203003\n",
      "\n",
      "2023-05-07 23:21:09 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-07 23:21:09 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-07 23:21:11 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-07 23:21:11 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 10, 'normalize_text': False, 'warmup': 0.1, 'weight_decay': 0.02}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 125306.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=16395\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 182206.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=2031\n",
      "Epoch: 1 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  22%|██▏       | 152/684 [03:16<11:20,  1.28s/it, loss: 1.124]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  23%|██▎       | 154/684 [03:18<11:20,  1.28s/it, loss: 1.279]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  29%|██▉       | 200/684 [04:17<10:23,  1.29s/it, loss: 0.976]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  30%|██▉       | 203/684 [04:21<10:20,  1.29s/it, loss: 1.940]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  34%|███▍      | 235/684 [05:03<09:38,  1.29s/it, loss: 1.250]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  35%|███▌      | 240/684 [05:09<09:31,  1.29s/it, loss: 1.027]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  45%|████▌     | 311/684 [06:41<08:01,  1.29s/it, loss: 0.936]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  52%|█████▏    | 358/684 [07:41<07:00,  1.29s/it, loss: 2.111]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  58%|█████▊    | 399/684 [08:34<06:07,  1.29s/it, loss: 1.254]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  65%|██████▍   | 444/684 [09:32<05:08,  1.28s/it, loss: 0.146]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  79%|███████▊  | 537/684 [11:31<03:09,  1.29s/it, loss: 0.481]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  88%|████████▊ | 601/684 [12:54<01:46,  1.29s/it, loss: 1.429]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  88%|████████▊ | 603/684 [12:56<01:44,  1.29s/it, loss: 1.542]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  94%|█████████▍| 644/684 [13:49<00:51,  1.28s/it, loss: 0.246]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  95%|█████████▌| 650/684 [13:57<00:43,  1.29s/it, loss: 1.280]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 684/684 [14:39<00:00,  1.29s/it, loss: 0.058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.63it/s,  acc: 0.542, f1: 0.486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.550\n",
      "Average epoch f1: 0.505\n",
      "Epoch: 2 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   8%|▊         | 57/684 [01:13<13:24,  1.28s/it, loss: 0.890]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  13%|█▎        | 88/684 [01:53<12:45,  1.28s/it, loss: 0.126]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  14%|█▍        | 97/684 [02:05<12:32,  1.28s/it, loss: 0.977]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  16%|█▌        | 108/684 [02:19<12:22,  1.29s/it, loss: 0.390]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  16%|█▌        | 111/684 [02:23<12:23,  1.30s/it, loss: 0.210]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  36%|███▌      | 244/684 [05:14<09:28,  1.29s/it, loss: 0.509]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  46%|████▌     | 315/684 [06:46<07:56,  1.29s/it, loss: 0.205]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  51%|█████▏    | 351/684 [07:32<07:08,  1.29s/it, loss: 0.085]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  61%|██████▏   | 420/684 [09:01<05:38,  1.28s/it, loss: 0.299]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  79%|███████▉  | 541/684 [11:36<03:03,  1.28s/it, loss: 0.489]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  83%|████████▎ | 568/684 [12:10<02:28,  1.28s/it, loss: 1.743]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  90%|█████████ | 617/684 [13:13<01:25,  1.28s/it, loss: 0.079]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  94%|█████████▍| 645/684 [13:49<00:49,  1.28s/it, loss: 0.116]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  96%|█████████▌| 655/684 [14:02<00:37,  1.28s/it, loss: 1.579]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  97%|█████████▋| 662/684 [14:11<00:28,  1.29s/it, loss: 1.411]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 684/684 [14:38<00:00,  1.28s/it, loss: 1.148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.64it/s,  acc: 0.552, f1: 0.483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.550\n",
      "Average epoch f1: 0.488\n",
      "Epoch: 3 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   2%|▏         | 17/684 [00:21<14:16,  1.28s/it, loss: 0.032]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:   7%|▋         | 50/684 [01:04<13:30,  1.28s/it, loss: 0.194]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:   8%|▊         | 58/684 [01:14<13:20,  1.28s/it, loss: 0.135]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  26%|██▋       | 180/684 [03:50<10:44,  1.28s/it, loss: 0.514]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  27%|██▋       | 187/684 [03:59<10:35,  1.28s/it, loss: 1.553]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  28%|██▊       | 191/684 [04:04<10:31,  1.28s/it, loss: 0.496]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  30%|██▉       | 205/684 [04:22<10:13,  1.28s/it, loss: 0.054]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  35%|███▌      | 242/684 [05:10<09:26,  1.28s/it, loss: 0.395]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  36%|███▌      | 243/684 [05:11<09:25,  1.28s/it, loss: 0.035]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  47%|████▋     | 322/684 [06:52<07:43,  1.28s/it, loss: 0.013]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  49%|████▉     | 336/684 [07:10<07:26,  1.28s/it, loss: 0.668]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  64%|██████▍   | 440/684 [09:23<05:13,  1.28s/it, loss: 1.306]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  75%|███████▌  | 516/684 [11:01<03:35,  1.28s/it, loss: 0.056]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  78%|███████▊  | 533/684 [11:23<03:13,  1.28s/it, loss: 0.075]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  85%|████████▌ | 582/684 [12:25<02:10,  1.28s/it, loss: 0.057]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 684/684 [14:35<00:00,  1.28s/it, loss: 0.019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.64it/s,  acc: 0.575, f1: 0.492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.564\n",
      "Average epoch f1: 0.488\n",
      "Epoch: 4 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  13%|█▎        | 88/684 [01:52<12:44,  1.28s/it, loss: 0.023]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  17%|█▋        | 113/684 [02:24<12:10,  1.28s/it, loss: 0.025]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  20%|█▉        | 135/684 [02:53<11:44,  1.28s/it, loss: 0.606]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  23%|██▎       | 155/684 [03:18<11:17,  1.28s/it, loss: 0.166]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  23%|██▎       | 159/684 [03:23<11:11,  1.28s/it, loss: 0.031]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  29%|██▉       | 199/684 [04:15<10:22,  1.28s/it, loss: 0.390]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  32%|███▏      | 217/684 [04:38<09:58,  1.28s/it, loss: 0.127]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  33%|███▎      | 227/684 [04:51<09:45,  1.28s/it, loss: 0.128]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  46%|████▌     | 315/684 [06:43<07:52,  1.28s/it, loss: 0.988]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  52%|█████▏    | 355/684 [07:35<07:00,  1.28s/it, loss: 0.038]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  52%|█████▏    | 359/684 [07:40<06:56,  1.28s/it, loss: 0.003]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  68%|██████▊   | 465/684 [09:55<04:39,  1.28s/it, loss: 0.046]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  76%|███████▌  | 521/684 [11:07<03:28,  1.28s/it, loss: 0.464]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  77%|███████▋  | 528/684 [11:16<03:19,  1.28s/it, loss: 0.233]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  82%|████████▏ | 558/684 [11:54<02:41,  1.28s/it, loss: 0.011]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 684/684 [14:35<00:00,  1.28s/it, loss: 0.063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.64it/s,  acc: 0.570, f1: 0.486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.573\n",
      "Average epoch f1: 0.490\n",
      "Epoch: 5 of 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   4%|▍         | 28/684 [00:35<14:02,  1.28s/it, loss: 0.177]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:   8%|▊         | 57/684 [01:13<13:22,  1.28s/it, loss: 0.154]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  10%|█         | 70/684 [01:29<13:07,  1.28s/it, loss: 0.010]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  15%|█▌        | 103/684 [02:12<12:24,  1.28s/it, loss: 0.007]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  23%|██▎       | 158/684 [03:22<11:12,  1.28s/it, loss: 0.030]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  34%|███▎      | 230/684 [04:54<09:42,  1.28s/it, loss: 0.003]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  55%|█████▌    | 379/684 [08:05<06:30,  1.28s/it, loss: 0.004]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  64%|██████▎   | 436/684 [09:18<05:17,  1.28s/it, loss: 0.064]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  65%|██████▌   | 445/684 [09:30<05:05,  1.28s/it, loss: 0.066]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  70%|███████   | 480/684 [10:14<04:21,  1.28s/it, loss: 0.439]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  72%|███████▏  | 491/684 [10:28<04:06,  1.28s/it, loss: 0.439]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  75%|███████▌  | 515/684 [10:59<03:36,  1.28s/it, loss: 0.007]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  88%|████████▊ | 603/684 [12:52<01:43,  1.28s/it, loss: 0.004]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  90%|████████▉ | 614/684 [13:06<01:29,  1.28s/it, loss: 0.296]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches:  96%|█████████▌| 658/684 [14:02<00:33,  1.28s/it, loss: 0.027]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 684/684 [14:35<00:00,  1.28s/it, loss: 0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 85/85 [00:32<00:00,  2.64it/s,  acc: 0.572, f1: 0.487]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.572\n",
      "Average epoch f1: 0.488\n",
      "Done!\n",
      "2023-05-08 00:36:58 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 1, run_best_acc: 0.5728825926780701, run_best_f1: 0.5045245289802551\n",
      "\n",
      "2023-05-08 00:36:58 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-08 00:36:58 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-08 00:37:06 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-08 00:37:06 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 10, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 270842.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=7806\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 266800.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=953\n",
      "Epoch: 1 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:58<00:00,  1.29s/it, loss: 0.838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.721, f1: 0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.718\n",
      "Average epoch f1: 0.766\n",
      "Epoch: 2 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.700, f1: 0.756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.708\n",
      "Average epoch f1: 0.760\n",
      "Epoch: 3 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.687, f1: 0.749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.692\n",
      "Average epoch f1: 0.752\n",
      "Epoch: 4 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.652, f1: 0.729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.668\n",
      "Average epoch f1: 0.738\n",
      "Epoch: 5 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.633, f1: 0.718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.641\n",
      "Average epoch f1: 0.723\n",
      "Epoch: 6 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.633, f1: 0.720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.633\n",
      "Average epoch f1: 0.720\n",
      "Epoch: 7 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.033]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.621, f1: 0.715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.628\n",
      "Average epoch f1: 0.718\n",
      "Epoch: 8 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 3.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.62it/s,  acc: 0.618, f1: 0.714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.619\n",
      "Average epoch f1: 0.714\n",
      "Epoch: 9 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.614, f1: 0.712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.616\n",
      "Average epoch f1: 0.713\n",
      "Epoch: 10 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.617, f1: 0.713]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.616\n",
      "Average epoch f1: 0.713\n",
      "Done!\n",
      "2023-05-08 01:49:16 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 1, run_best_acc: 0.7180168032646179, run_best_f1: 0.7657316327095032\n",
      "\n",
      "2023-05-08 01:49:16 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-08 01:49:16 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-08 01:49:18 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-08 01:49:18 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 10, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.02}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 179707.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=7806\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 348958.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=953\n",
      "Epoch: 1 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [07:00<00:00,  1.29s/it, loss: 0.130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.699, f1: 0.767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.713\n",
      "Average epoch f1: 0.782\n",
      "Epoch: 2 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:58<00:00,  1.28s/it, loss: 0.888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.62it/s,  acc: 0.656, f1: 0.740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.672\n",
      "Average epoch f1: 0.751\n",
      "Epoch: 3 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.020]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.655, f1: 0.739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.658\n",
      "Average epoch f1: 0.741\n",
      "Epoch: 4 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.647, f1: 0.732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.652\n",
      "Average epoch f1: 0.736\n",
      "Epoch: 5 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.61it/s,  acc: 0.652, f1: 0.735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.650\n",
      "Average epoch f1: 0.734\n",
      "Epoch: 6 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.62it/s,  acc: 0.645, f1: 0.729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.649\n",
      "Average epoch f1: 0.732\n",
      "Epoch: 7 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.62it/s,  acc: 0.640, f1: 0.725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.643\n",
      "Average epoch f1: 0.728\n",
      "Epoch: 8 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.62it/s,  acc: 0.640, f1: 0.726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.640\n",
      "Average epoch f1: 0.726\n",
      "Epoch: 9 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.633, f1: 0.721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.636\n",
      "Average epoch f1: 0.723\n",
      "Epoch: 10 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.62it/s,  acc: 0.637, f1: 0.723]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.635\n",
      "Average epoch f1: 0.722\n",
      "Done!\n",
      "2023-05-08 03:01:46 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 1, run_best_acc: 0.713405191898346, run_best_f1: 0.7815702557563782\n",
      "\n",
      "2023-05-08 03:01:46 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-08 03:01:46 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-08 03:01:48 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-08 03:01:48 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 10, 'n_neg_samples': 3, 'normalize_text': False, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 13153.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=7806\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 326223.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=953\n",
      "Epoch: 1 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  68%|██████▊   | 222/326 [04:46<02:14,  1.29s/it, loss: 0.774]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.64it/s,  acc: 0.616, f1: 0.711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.630\n",
      "Average epoch f1: 0.721\n",
      "Epoch: 2 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  10%|▉         | 32/326 [00:41<06:19,  1.29s/it, loss: 0.558]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:58<00:00,  1.28s/it, loss: 0.915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.64it/s,  acc: 0.616, f1: 0.710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.619\n",
      "Average epoch f1: 0.713\n",
      "Epoch: 3 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  85%|████████▌ | 278/326 [05:57<01:01,  1.29s/it, loss: 0.039]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:58<00:00,  1.28s/it, loss: 0.104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.64it/s,  acc: 0.593, f1: 0.700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.603\n",
      "Average epoch f1: 0.705\n",
      "Epoch: 4 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  51%|█████     | 166/326 [03:33<03:26,  1.29s/it, loss: 0.008]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:58<00:00,  1.28s/it, loss: 0.096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.64it/s,  acc: 0.599, f1: 0.703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.597\n",
      "Average epoch f1: 0.703\n",
      "Epoch: 5 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  77%|███████▋  | 252/326 [05:24<01:35,  1.29s/it, loss: 0.025]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:58<00:00,  1.28s/it, loss: 0.304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.586, f1: 0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.592\n",
      "Average epoch f1: 0.701\n",
      "Epoch: 6 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  66%|██████▋   | 216/326 [04:38<02:21,  1.29s/it, loss: 0.049]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.64it/s,  acc: 0.585, f1: 0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.585\n",
      "Average epoch f1: 0.698\n",
      "Epoch: 7 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   6%|▌         | 20/326 [00:25<06:35,  1.29s/it, loss: 0.002]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.577, f1: 0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.581\n",
      "Average epoch f1: 0.696\n",
      "Epoch: 8 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  60%|██████    | 197/326 [04:13<02:46,  1.29s/it, loss: 0.004]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.64it/s,  acc: 0.571, f1: 0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.574\n",
      "Average epoch f1: 0.693\n",
      "Epoch: 9 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   3%|▎         | 9/326 [00:11<06:50,  1.30s/it, loss: 0.006]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.63it/s,  acc: 0.564, f1: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.567\n",
      "Average epoch f1: 0.690\n",
      "Epoch: 10 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  89%|████████▊ | 289/326 [06:12<00:47,  1.29s/it, loss: 0.009]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 0.036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.64it/s,  acc: 0.559, f1: 0.686]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.561\n",
      "Average epoch f1: 0.687\n",
      "Done!\n",
      "2023-05-08 04:14:13 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 1, run_best_acc: 0.6302266120910645, run_best_f1: 0.7211500406265259\n",
      "\n",
      "2023-05-08 04:14:13 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-08 04:14:13 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-08 04:14:25 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-08 04:14:25 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 10, 'n_neg_samples': 3, 'normalize_text': False, 'warmup': 0.1, 'weight_decay': 0.02}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 187056.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=7806\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 329048.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=953\n",
      "Epoch: 1 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  67%|██████▋   | 218/326 [04:41<02:19,  1.29s/it, loss: 1.562]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:59<00:00,  1.29s/it, loss: 1.918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.66it/s,  acc: 0.619, f1: 0.723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.613\n",
      "Average epoch f1: 0.722\n",
      "Epoch: 2 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  32%|███▏      | 105/326 [02:15<04:44,  1.29s/it, loss: 0.249]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:58<00:00,  1.28s/it, loss: 0.113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.65it/s,  acc: 0.610, f1: 0.714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.615\n",
      "Average epoch f1: 0.719\n",
      "Epoch: 3 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:   1%|          | 3/326 [00:03<06:57,  1.29s/it, loss: 0.046]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:58<00:00,  1.28s/it, loss: 0.417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.65it/s,  acc: 0.605, f1: 0.713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.607\n",
      "Average epoch f1: 0.714\n",
      "Epoch: 4 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  51%|█████     | 167/326 [03:34<03:24,  1.28s/it, loss: 0.095]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.64it/s,  acc: 0.603, f1: 0.710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.604\n",
      "Average epoch f1: 0.711\n",
      "Epoch: 5 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  34%|███▍      | 112/326 [02:23<04:35,  1.29s/it, loss: 0.008]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.64it/s,  acc: 0.593, f1: 0.705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.599\n",
      "Average epoch f1: 0.708\n",
      "Epoch: 6 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  93%|█████████▎| 303/326 [06:29<00:29,  1.29s/it, loss: 0.545]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.65it/s,  acc: 0.587, f1: 0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.591\n",
      "Average epoch f1: 0.704\n",
      "Epoch: 7 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  26%|██▌       | 85/326 [01:49<05:09,  1.28s/it, loss: 0.002]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.64it/s,  acc: 0.589, f1: 0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.588\n",
      "Average epoch f1: 0.701\n",
      "Epoch: 8 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  98%|█████████▊| 321/326 [06:52<00:06,  1.29s/it, loss: 0.041]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.65it/s,  acc: 0.585, f1: 0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.587\n",
      "Average epoch f1: 0.700\n",
      "Epoch: 9 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  46%|████▋     | 151/326 [03:13<03:45,  1.29s/it, loss: 0.010]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:57<00:00,  1.28s/it, loss: 0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.65it/s,  acc: 0.579, f1: 0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.582\n",
      "Average epoch f1: 0.697\n",
      "Epoch: 10 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  86%|████████▌ | 279/326 [05:58<01:00,  1.29s/it, loss: 0.054]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "train batches: 100%|██████████| 326/326 [06:58<00:00,  1.28s/it, loss: 0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 40/40 [00:15<00:00,  2.65it/s,  acc: 0.571, f1: 0.692]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.575\n",
      "Average epoch f1: 0.694\n",
      "Done!\n",
      "2023-05-08 05:26:39 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 1, run_best_acc: 0.6148208379745483, run_best_f1: 0.7218205332756042\n",
      "\n",
      "2023-05-08 05:26:39 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-08 05:26:39 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-08 05:26:40 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-08 05:26:40 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 10, 'n_neg_samples': 5, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 156358.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=10260\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 275446.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=1261\n",
      "Epoch: 1 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:09<00:00,  1.28s/it, loss: 0.708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.761, f1: 0.743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.762\n",
      "Average epoch f1: 0.751\n",
      "Epoch: 2 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:06<00:00,  1.28s/it, loss: 0.145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.719, f1: 0.707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.735\n",
      "Average epoch f1: 0.722\n",
      "Epoch: 3 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:08<00:00,  1.28s/it, loss: 0.045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.695, f1: 0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.706\n",
      "Average epoch f1: 0.700\n",
      "Epoch: 4 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:06<00:00,  1.28s/it, loss: 0.013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.701, f1: 0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.699\n",
      "Average epoch f1: 0.695\n",
      "Epoch: 5 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:08<00:00,  1.28s/it, loss: 0.068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.62it/s,  acc: 0.691, f1: 0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.697\n",
      "Average epoch f1: 0.693\n",
      "Epoch: 6 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:05<00:00,  1.27s/it, loss: 0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.672, f1: 0.676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.681\n",
      "Average epoch f1: 0.682\n",
      "Epoch: 7 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:08<00:00,  1.28s/it, loss: 0.004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.662, f1: 0.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.667\n",
      "Average epoch f1: 0.674\n",
      "Epoch: 8 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:05<00:00,  1.28s/it, loss: 0.006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.654, f1: 0.667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.659\n",
      "Average epoch f1: 0.670\n",
      "Epoch: 9 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:08<00:00,  1.28s/it, loss: 0.002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.645, f1: 0.661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.650\n",
      "Average epoch f1: 0.664\n",
      "Epoch: 10 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:06<00:00,  1.28s/it, loss: 0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.641, f1: 0.659]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.644\n",
      "Average epoch f1: 0.660\n",
      "Done!\n",
      "2023-05-08 07:01:16 model_05_cross_encoder_retrieval:INFO\n",
      "run_best_epoch: 1, run_best_acc: 0.7624387145042419, run_best_f1: 0.751181960105896\n",
      "\n",
      "2023-05-08 07:01:16 model_05_cross_encoder_retrieval:INFO\n",
      "== CURRENT BEST F1: 0.8339534997940063\n",
      "\n",
      "2023-05-08 07:01:16 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 5, 'n_neg_samples': 3, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-08 07:01:18 model_05_cross_encoder_retrieval:INFO\n",
      "== RUN\n",
      "\n",
      "2023-05-08 07:01:18 model_05_cross_encoder_retrieval:INFO\n",
      "{'batch_size': 24, 'claims_paths': [PosixPath('/Users/johnsonzhou/git/comp90042-project/data/train-claims.json')], 'claims_shortlist_paths': [PosixPath('result/pipeline/shortlisting_v2/train_retrieved_evidences_max_500_no_rel.json')], 'dropout': None, 'lr': 5e-05, 'max_length': 512, 'n_epochs': 10, 'n_neg_samples': 5, 'normalize_text': True, 'warmup': 0.1, 'weight_decay': 0.02}\n",
      "\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:00<00:00, 268358.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=10260\n",
      "Torch device is 'mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 255305.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated dataset n=1261\n",
      "Epoch: 1 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:09<00:00,  1.28s/it, loss: 1.404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 1.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.593, f1: 0.647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.594\n",
      "Average epoch f1: 0.651\n",
      "Epoch: 2 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:11<00:00,  1.29s/it, loss: 0.095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.59it/s,  acc: 0.551, f1: 0.619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.568\n",
      "Average epoch f1: 0.631\n",
      "Epoch: 3 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:18<00:00,  1.31s/it, loss: 0.020]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.62it/s,  acc: 0.587, f1: 0.636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.571\n",
      "Average epoch f1: 0.629\n",
      "Epoch: 4 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:10<00:00,  1.29s/it, loss: 0.085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.597, f1: 0.639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.592\n",
      "Average epoch f1: 0.638\n",
      "Epoch: 5 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:08<00:00,  1.28s/it, loss: 0.296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.62it/s,  acc: 0.602, f1: 0.641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.600\n",
      "Average epoch f1: 0.641\n",
      "Epoch: 6 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:09<00:00,  1.28s/it, loss: 0.032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.589, f1: 0.634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.595\n",
      "Average epoch f1: 0.638\n",
      "Epoch: 7 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:07<00:00,  1.28s/it, loss: 0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.588, f1: 0.632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.589\n",
      "Average epoch f1: 0.634\n",
      "Epoch: 8 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:09<00:00,  1.28s/it, loss: 0.023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.599, f1: 0.638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.594\n",
      "Average epoch f1: 0.636\n",
      "Epoch: 9 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 428/428 [09:08<00:00,  1.28s/it, loss: 0.016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss: 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 53/53 [00:20<00:00,  2.63it/s,  acc: 0.589, f1: 0.633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch accuracy: 0.594\n",
      "Average epoch f1: 0.635\n",
      "Epoch: 10 of 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  91%|█████████ | 388/428 [08:27<00:52,  1.31s/it, loss: 0.003]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m== RUN\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m logger\u001b[39m.\u001b[39minfo(hyperparam)\n\u001b[0;32m---> 18\u001b[0m accuracy, f1, epoch \u001b[39m=\u001b[39m training_loop(model\u001b[39m=\u001b[39;49mmodel, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhyperparam)\n\u001b[1;32m     20\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrun_best_epoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, run_best_acc: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m}\u001b[39;00m\u001b[39m, run_best_f1: \u001b[39m\u001b[39m{\u001b[39;00mf1\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m f1 \u001b[39m>\u001b[39m best_f1:\n",
      "Cell \u001b[0;32mIn[4], line 95\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, claims_paths, claims_shortlist_paths, save_path, n_neg_samples, warmup, lr, weight_decay, normalize_text, max_length, dropout, n_epochs, batch_size)\u001b[0m\n\u001b[1;32m     92\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, labels)\n\u001b[1;32m     94\u001b[0m \u001b[39m# Backward + optimizer\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     96\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     98\u001b[0m \u001b[39m# Update running loss\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/comp90042_project/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/comp90042_project/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with SimpleLogger(\"model_05_cross_encoder_retrieval\") as logger:\n",
    "    logger.set_stream_handler()\n",
    "    logger.set_file_handler(\n",
    "        log_path=LOG_PATH,\n",
    "        filename=\"model_05_hyperparam_tuning.txt\"\n",
    "    )\n",
    "    best_f1 = -1\n",
    "    best_params = {}\n",
    "    for hyperparam in hyperparams:\n",
    "        model = BertCrossEncoderClassifier(\n",
    "            pretrained_name=\"bert-base-uncased\",\n",
    "            n_classes=2,\n",
    "            device=TORCH_DEVICE\n",
    "        )\n",
    "        logger.info(\"== RUN\")\n",
    "        logger.info(hyperparam)\n",
    "        \n",
    "        accuracy, f1, epoch = training_loop(model=model, **hyperparam)\n",
    "        \n",
    "        logger.info(f\"run_best_epoch: {epoch}, run_best_acc: {accuracy}, run_best_f1: {f1}\")\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_params = hyperparam\n",
    "        \n",
    "        logger.info(f\"== CURRENT BEST F1: {best_f1}\")\n",
    "        logger.info(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp90042_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
