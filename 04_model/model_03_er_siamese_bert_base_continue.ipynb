{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 03\n",
    "\n",
    "Evidence retrieval using a Siamese BERT classification model.\n",
    "This is similar to Model 01, however, it only uses official pre-trained models from hugging face.\n",
    "\n",
    "This extends model 03 by continuing the training with greater proportion of negative samples.\n",
    "\n",
    "Ref:\n",
    "- [Hugging face pre-trained models](https://huggingface.co/transformers/v3.3.1/pretrained_models.html)\n",
    "- [Hugging face guide to fine-tuning](https://huggingface.co/transformers/v3.3.1/custom_datasets.html)\n",
    "- [Hugging face guide to fine-tuning easy](https://huggingface.co/docs/transformers/training)\n",
    "- [SO Guide](https://stackoverflow.com/a/64156912)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to project root\n",
    "from pathlib import Path\n",
    "import os\n",
    "ROOT_DIR = Path.cwd()\n",
    "while not ROOT_DIR.joinpath(\"src\").exists():\n",
    "    ROOT_DIR = ROOT_DIR.parent\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = ROOT_DIR.joinpath(\"./result/models/*\")\n",
    "DATA_PATH = ROOT_DIR.joinpath(\"./data/*\")\n",
    "NER_PATH = ROOT_DIR.joinpath(\"./result/ner/*\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/comp90042_project/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device is 'mps'\n"
     ]
    }
   ],
   "source": [
    "# Imports and dependencies\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Linear, Module, CrossEntropyLoss, Dropout\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from torch.nn.functional import relu, softmax\n",
    "from torcheval.metrics import BinaryAccuracy, BinaryF1Score, BinaryRecall\n",
    "\n",
    "from src.torch_utils import get_torch_device\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Union, Tuple\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from math import exp\n",
    "\n",
    "TORCH_DEVICE = get_torch_device()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ClaimEvidencePair:\n",
    "    claim_id:str\n",
    "    evidence_id:str\n",
    "    label:int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        claims_paths:List[Path],\n",
    "        claims_shortlist_paths:List[Path],\n",
    "        evidence_path:Path,\n",
    "        evidence_shortlists:List[Path] = None,\n",
    "        device = None,\n",
    "        n_neg_shortlist:int = 10,\n",
    "        n_neg_general:int = 10,\n",
    "        verbose:bool=True\n",
    "    ) -> None:\n",
    "        super(SiameseDataset, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        self.device = device\n",
    "        self.n_neg_shortlist = n_neg_shortlist\n",
    "        self.n_neg_general = n_neg_general\n",
    "\n",
    "        # Load claims data from json, this is a list as we could use\n",
    "        # multiple json files in the same dataset\n",
    "        self.claims = dict()\n",
    "        for json_file in claims_paths:\n",
    "            with open(json_file, mode=\"r\") as f:\n",
    "                self.claims.update(json.load(fp=f))\n",
    "                # print(f\"loaded claims: {json_file}\")\n",
    "        \n",
    "        # Load the pre-retrieved shortlist of evidences by claim\n",
    "        self.claims_shortlist = dict()\n",
    "        for json_file in claims_shortlist_paths:\n",
    "            with open(json_file, mode=\"r\") as f:\n",
    "                self.claims_shortlist.update(json.load(fp=f))\n",
    "                # print(f\"loaded claims_shortlist: {json_file}\")\n",
    "        \n",
    "        # Load evidence library\n",
    "        self.evidence = dict()\n",
    "        with open(evidence_path, mode=\"r\") as f:\n",
    "            self.evidence.update(json.load(fp=f))\n",
    "            # print(f\"loaded evidences: {json_file}\")\n",
    "        \n",
    "        # Load the evidence shortlists if available\n",
    "        # Reduce the overall evidence list to the shortlist\n",
    "        if evidence_shortlists is not None:\n",
    "            self.evidence_shortlist = set()\n",
    "            for json_file in evidence_shortlists:\n",
    "                with open(json_file, mode=\"r\") as f:\n",
    "                    self.evidence_shortlist.update(json.load(fp=f))\n",
    "                    # print(f\"loaded evidence shortlist: {json_file}\")\n",
    "        \n",
    "        # print(f\"n_evidences: {len(self.evidence)}\")\n",
    "        \n",
    "        # Generate the data\n",
    "        self.data = self.__generate_data()\n",
    "        return\n",
    "\n",
    "    def __generate_data(self):\n",
    "        print(\"Generate siamese dataset\")\n",
    "        \n",
    "        data = []\n",
    "        for claim_id, claim in tqdm(\n",
    "            iterable=self.claims.items(),\n",
    "            desc=\"claims\",\n",
    "            disable=not self.verbose\n",
    "        ):\n",
    "            # Check if we have evidences supplied, this will inform\n",
    "            # whether this is for training\n",
    "            is_training = \"evidences\" in claim.keys()\n",
    "            pos_evidence_ids = set()\n",
    "            \n",
    "            # Get positive samples from evidences with label=1\n",
    "            if is_training:\n",
    "                pos_evidence_ids.update(claim[\"evidences\"])\n",
    "\n",
    "                for evidence_id in pos_evidence_ids:\n",
    "                    data.append(ClaimEvidencePair(\n",
    "                        claim_id=claim_id,\n",
    "                        evidence_id=evidence_id,\n",
    "                        label=1\n",
    "                    ))\n",
    "                    \n",
    "            # Get negative samples from pre-retrieved evidences\n",
    "            # for each claim with label=0\n",
    "            retrieved_evidence_ids = self.claims_shortlist.get(claim_id, [])\n",
    "            if len(retrieved_evidence_ids) > 0:\n",
    "                retrieved_neg_evidence_ids = random.sample(\n",
    "                    population=retrieved_evidence_ids,\n",
    "                    k=min(self.n_neg_shortlist, len(retrieved_evidence_ids))\n",
    "                )\n",
    "                \n",
    "                # Generate claim and shortlisted negative evidence pairs\n",
    "                for evidence_id in retrieved_neg_evidence_ids:\n",
    "                    data.append(ClaimEvidencePair(\n",
    "                        claim_id=claim_id,\n",
    "                        evidence_id=evidence_id,\n",
    "                        label=0\n",
    "                    ))\n",
    "            \n",
    "            # Get negative samples from shortlisted evidences list with label=0\n",
    "            if len(self.evidence_shortlist) > 0:\n",
    "                shortlist_neg_evidence_ids = random.sample(\n",
    "                    population=self.evidence_shortlist,\n",
    "                    k=min(self.n_neg_general, len(self.evidence_shortlist))\n",
    "                )\n",
    "                \n",
    "                # Generate claim and shortlisted negative evidence pairs\n",
    "                for evidence_id in shortlist_neg_evidence_ids:\n",
    "                    data.append(ClaimEvidencePair(\n",
    "                        claim_id=claim_id,\n",
    "                        evidence_id=evidence_id,\n",
    "                        label=0\n",
    "                    ))\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        print(f\"Generated data n={len(data)}\")\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[Union[str, torch.Tensor]]:\n",
    "        # Fetch the required data rows\n",
    "        data = self.data[idx]\n",
    "        \n",
    "        # Get the label\n",
    "        label = torch.tensor(data.label, device=self.device)\n",
    "        \n",
    "        # Get text ids\n",
    "        claim_id = data.claim_id\n",
    "        evidence_id = data.evidence_id\n",
    "        \n",
    "        # Get text\n",
    "        claim_text = self.claims[claim_id][\"claim_text\"]\n",
    "        evidence_text = self.evidence[evidence_id]\n",
    "\n",
    "        return (claim_text, evidence_text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE WILL GENERATE THE DATASET PER EPOCH SO TO RANDOMISE THE NEGATIVE SAMPLES\n",
    "\n",
    "# train_data = SiameseDataset(\n",
    "#     claims_paths=[DATA_PATH.with_name(\"train-claims.json\")],\n",
    "#     claims_shortlist_paths=[NER_PATH.with_name(\"train_claim_evidence_retrieved.json\")],\n",
    "#     evidence_shortlists=[NER_PATH.with_name(\"shortlist_train_claim_evidence_retrieved.json\")],\n",
    "#     evidence_path=DATA_PATH.with_name(\"evidence.json\"),\n",
    "#     device=TORCH_DEVICE,\n",
    "#     n_neg_shortlist=100,\n",
    "#     n_neg_general=100\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseClassifierBert(Module):\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            pretrained_name:str,\n",
    "            device,\n",
    "            **kwargs\n",
    "        ) -> None:\n",
    "        super(SiameseClassifierBert, self).__init__(**kwargs)\n",
    "        self.device = device\n",
    "        \n",
    "        # Use a pretrained tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_name)\n",
    "        \n",
    "        # Use a pretrained model\n",
    "        self.bert = BertModel.from_pretrained(pretrained_name)\n",
    "        self.bert.to(device=device)\n",
    "        \n",
    "        # Classification layers\n",
    "        self.linear1 = Linear(2304, 1024, bias=True, device=device)\n",
    "        self.linear2 = Linear(1024, 512, bias=True, device=device)\n",
    "        self.linear3 = Linear(512, 2, bias=True, device=device)\n",
    "        self.relu = relu\n",
    "        self.softmax = softmax\n",
    "        self.dropout_in = Dropout(p=0.2)\n",
    "        self.dropout_out = Dropout(p=0.5)\n",
    "        \n",
    "        # print(self.tokenizer)\n",
    "        # print(self.bert)\n",
    "        # print(self.linear1)\n",
    "        # print(self.linear2)\n",
    "        # print(self.activation)\n",
    "        # print(self.softmax)\n",
    "        return\n",
    "        \n",
    "    def forward(self, claim_texts, evidence_texts) -> Tuple[torch.Tensor]:\n",
    "        \n",
    "        # Run the tokenizer\n",
    "        t_kwargs = {\n",
    "            \"return_tensors\": \"pt\",\n",
    "            \"padding\": True,\n",
    "            \"truncation\": True,\n",
    "            \"max_length\": 100,\n",
    "            \"add_special_tokens\":True\n",
    "        }\n",
    "        claim_x = self.tokenizer(claim_texts, **t_kwargs)\n",
    "        evidence_x = self.tokenizer(evidence_texts, **t_kwargs)\n",
    "        \n",
    "        claim_x = claim_x[\"input_ids\"].to(device=self.device)\n",
    "        evidence_x = evidence_x[\"input_ids\"].to(device=self.device)\n",
    "        \n",
    "        # Run Bert\n",
    "        claim_x = self.bert(claim_x, return_dict=True).pooler_output\n",
    "        evidence_x = self.bert(evidence_x, return_dict=True).pooler_output\n",
    "        # dim=768\n",
    "        \n",
    "        # Concatenate the two embeddings\n",
    "        x = torch.cat((claim_x, evidence_x, claim_x - evidence_x), dim=1)\n",
    "        # dim=2304\n",
    "        \n",
    "        # Run classification layers\n",
    "        x = self.dropout_in(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout_out(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout_out(x)\n",
    "        x = self.linear3(x)\n",
    "        \n",
    "        # Create the predictions\n",
    "        y = self.softmax(x, dim=-1)\n",
    "        \n",
    "        return (y, claim_x, evidence_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are continuing to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SiameseClassifierBert(\n",
    "#     pretrained_name=\"bert-base-uncased\",\n",
    "#     device=TORCH_DEVICE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time = datetime.now().strftime('%Y_%m_%d_%H_%M')\n",
    "MODEL_NAME = f\"model_03_base_run_01_continue.pth\"\n",
    "N_EPOCHS = 4\n",
    "BATCH_SIZE = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL_PATH.with_name(MODEL_NAME), mode=\"rb\") as f:\n",
    "    model = torch.load(f, map_location=TORCH_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=0.000002\n",
    ") #! Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 154/154 [00:00<00:00, 469.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=3532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_data = SiameseDataset(\n",
    "    claims_paths=[DATA_PATH.with_name(\"dev-claims.json\")],\n",
    "    claims_shortlist_paths=[NER_PATH.with_name(\"dev_claim_evidence_retrieved.json\")],\n",
    "    evidence_shortlists=[NER_PATH.with_name(\"shortlist_dev_claim_evidence_retrieved.json\")],\n",
    "    evidence_path=DATA_PATH.with_name(\"evidence.json\"),\n",
    "    device=TORCH_DEVICE,\n",
    "    n_neg_shortlist=10,\n",
    "    n_neg_general=10\n",
    ")\n",
    "\n",
    "dev_dataloader = DataLoader(\n",
    "    dataset=dev_data,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-06.\n",
      "Epoch: 0 of 4\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:07<00:00, 172.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=28097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 440/440 [06:15<00:00,  1.17it/s, loss: 1.091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-06.\n",
      "Average epoch loss: 1.0903123059056021\n",
      "Saved model to: /Users/johnsonzhou/git/comp90042-project/result/models/model_03_base_run_01_continue.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev batches: 100%|██████████| 56/56 [00:16<00:00,  3.31it/s,  acc: 0.882 f1: 0.604 rec: 0.604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch accuracy on dev: 0.877\n",
      "Epoch f1 on dev: 0.602\n",
      "Epoch recall on dev: 0.602\n",
      "\n",
      "Epoch: 1 of 4\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:07<00:00, 174.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=28097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches: 100%|██████████| 440/440 [06:15<00:00,  1.17it/s, loss: 0.940]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-06.\n",
      "Average epoch loss: 1.0925235448235815\n",
      "Epoch: 2 of 4\n",
      "\n",
      "Generate siamese dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "claims: 100%|██████████| 1228/1228 [00:06<00:00, 182.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data n=28097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train batches:  54%|█████▍    | 239/440 [03:26<02:53,  1.16it/s, loss: 1.091]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(predictions, labels)\n\u001b[1;32m     48\u001b[0m \u001b[39m# Backward + optimiser\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     50\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     52\u001b[0m \u001b[39m# Update running loss\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/comp90042_project/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/comp90042_project/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metric_accuracy = BinaryAccuracy()\n",
    "metric_f1 = BinaryF1Score()\n",
    "metric_recall = BinaryF1Score()\n",
    "\n",
    "scheduler = LinearLR(\n",
    "    optimizer=optimizer,\n",
    "    start_factor=1,\n",
    "    end_factor=1,\n",
    "    total_iters=int(N_EPOCHS/10),\n",
    "    verbose=True\n",
    ")\n",
    "last_epoch_loss = 999\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    print(f\"Epoch: {epoch} of {N_EPOCHS}\\n\")\n",
    "    \n",
    "    # Run training\n",
    "    model.train()\n",
    "    \n",
    "    train_data = SiameseDataset(\n",
    "        claims_paths=[DATA_PATH.with_name(\"train-claims.json\")],\n",
    "        claims_shortlist_paths=[NER_PATH.with_name(\"train_claim_evidence_retrieved.json\")],\n",
    "        evidence_shortlists=[NER_PATH.with_name(\"shortlist_train_claim_evidence_retrieved.json\")],\n",
    "        evidence_path=DATA_PATH.with_name(\"evidence.json\"),\n",
    "        device=TORCH_DEVICE,\n",
    "        n_neg_shortlist=10,\n",
    "        n_neg_general=10\n",
    "    )\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        shuffle=True,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    train_batches = tqdm(train_dataloader, desc=\"train batches\")\n",
    "    running_losses = []\n",
    "    for batch in train_batches:\n",
    "        claim_texts, evidence_texts, labels = batch\n",
    "        \n",
    "        # Reset optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward + loss\n",
    "        predictions, *_ = model(claim_texts, evidence_texts)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        \n",
    "        # Backward + optimiser\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update running loss\n",
    "        batch_loss = loss.item() * len(batch)\n",
    "        running_losses.append(batch_loss)\n",
    "        \n",
    "        train_batches.postfix = f\"loss: {batch_loss:.3f}\"\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    epoch_loss = np.average(running_losses)\n",
    "    print(f\"Average epoch loss: {epoch_loss}\")\n",
    "    \n",
    "    # Save model\n",
    "    if epoch_loss <= last_epoch_loss:\n",
    "        torch.save(model, MODEL_PATH.with_name(MODEL_NAME))\n",
    "        print(f\"Saved model to: {MODEL_PATH.with_name(MODEL_NAME)}\")\n",
    "    last_epoch_loss = epoch_loss\n",
    "    \n",
    "    # Evaluate every 5 epochs\n",
    "    if epoch % 2 != 0:\n",
    "        continue\n",
    "    \n",
    "    # Run evaluation\n",
    "    model.eval()\n",
    "    \n",
    "    dev_batches = tqdm(dev_dataloader, desc=\"dev batches\")\n",
    "    dev_acc = []\n",
    "    dev_f1 = []\n",
    "    dev_rec = []\n",
    "    for batch in dev_batches:\n",
    "        claim_texts, evidence_texts, labels = batch\n",
    "        \n",
    "        # Forward\n",
    "        predictions, *_ = model(claim_texts, evidence_texts)\n",
    "        \n",
    "        # Prediction\n",
    "        _, predicted = torch.max(predictions, dim=-1)\n",
    "        \n",
    "        # Metrics\n",
    "        metric_accuracy.update(predicted.cpu(), labels.cpu())\n",
    "        metric_f1.update(predicted.cpu(), labels.cpu())\n",
    "        metric_recall.update(predicted.cpu(), labels.cpu())\n",
    "        \n",
    "        acc = metric_accuracy.compute()\n",
    "        f1 = metric_f1.compute()\n",
    "        rec = metric_recall.compute()\n",
    "        \n",
    "        dev_acc.append(acc)\n",
    "        dev_f1.append(f1)\n",
    "        dev_rec.append(rec)\n",
    "        \n",
    "        dev_batches.postfix = \\\n",
    "            f\" acc: {acc:.3f}\" \\\n",
    "            + f\" f1: {f1:.3f}\" \\\n",
    "            + f\" rec: {rec:.3f}\"\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    val_acc = np.mean(dev_acc)\n",
    "    val_f1 = np.mean(dev_f1)\n",
    "    val_rec = np.mean(dev_rec)\n",
    "    \n",
    "    print(f\"Epoch accuracy on dev: {val_acc:.3f}\")\n",
    "    print(f\"Epoch f1 on dev: {val_f1:.3f}\")\n",
    "    print(f\"Epoch recall on dev: {val_rec:.3f}\\n\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp90042_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
